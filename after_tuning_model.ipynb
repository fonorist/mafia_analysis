{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8807c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config set. SEED=42, TAU=300\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 1) Imports & Config\n",
    "# ==============================\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Models\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss, f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Utils\n",
    "from pprint import pprint\n",
    "\n",
    "# Repro\n",
    "SEED = 42\n",
    "TAU  = 300   # keep at 300 as you requested\n",
    "np.random.seed(SEED)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "print(f\"Config set. SEED={SEED}, TAU={TAU}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e6ecfd",
   "metadata": {},
   "source": [
    "### DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb568c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\George\\AppData\\Local\\Temp\\ipykernel_12504\\4277500127.py:6: DtypeWarning: Columns (16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(DATA_CSV)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (802820, 21) columns: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\George\\AppData\\Local\\Temp\\ipykernel_12504\\4277500127.py:91: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for (pid, role), g in d.groupby(['player_id','role'], sort=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes | X: (160564, 105) | y: (160564,)\n",
      "Split sizes | train: 136480 cal: 24084 test: 24084\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_CSV = Path(\"cleaned/mafia_clean.csv\")   # put the CSV next to this notebook or provide an absolute path\n",
    "OUT_DIR  = Path(\"cleaned\"); OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "print(\"Loaded:\", df.shape, \"columns:\", len(df.columns))\n",
    "assert {'id','game_id','player_id','role','team','game_points','team_win'}.issubset(df.columns), \\\n",
    "    \"Missing required columns in the cleaned dataset.\"\n",
    "\n",
    "# Basic coercions\n",
    "df['id'] = pd.to_numeric(df['id'], errors='coerce').astype('int64')\n",
    "df['game_id'] = pd.to_numeric(df['game_id'], errors='coerce').astype('int64')\n",
    "df['player_id'] = pd.to_numeric(df['player_id'], errors='coerce').astype('int64')\n",
    "df['team_win'] = pd.to_numeric(df['team_win'], errors='coerce').astype('int8')\n",
    "df['team'] = df['team'].astype('category')\n",
    "df['role'] = df['role'].astype('category')\n",
    "\n",
    "# Seat/position optional column name normalization (if present)\n",
    "if 'place' in df.columns:\n",
    "    df['place'] = pd.to_numeric(df['place'], errors='coerce').fillna(0).astype('int16')\n",
    "\n",
    "# Meta eras\n",
    "bins   = [0, 200_000, 400_000, 600_000, 800_000, 1_000_000_000]\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "df['meta_period'] = pd.cut(df['id'], bins=bins, labels=labels, include_lowest=True).astype('int8')\n",
    "\n",
    "# Gap per player (id as time proxy)\n",
    "df = df.sort_values(['player_id','id']).copy()\n",
    "df['gap_id'] = df.groupby('player_id')['id'].diff().fillna(0).astype('int64')\n",
    "df['gap_id_clipped'] = np.clip(df['gap_id'], 0, 5000).astype('int32')\n",
    "GAP_THRESH = 381  # adjust via quantiles if desired\n",
    "df['long_break_flag'] = (df['gap_id'] >= GAP_THRESH).astype('int8')\n",
    "\n",
    "# Restore global order\n",
    "df = df.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "def compute_elos(dfin, init=1500, k=24, tau=300.0):\n",
    "    d = dfin.sort_values('id').copy()\n",
    "    elo_global, elo_side, elo_role = {}, {}, {}\n",
    "    last_seen = {}\n",
    "    outs = []\n",
    "\n",
    "    for gid, g in d.groupby('game_id', sort=False):\n",
    "        cur = g.copy()\n",
    "        cur['pre_elo']      = [elo_global.get(pid, init) for pid in cur['player_id']]\n",
    "        cur['pre_elo_side'] = [elo_side.get((pid, team), init) for pid, team in zip(cur['player_id'], cur['team'])]\n",
    "        cur['pre_elo_role'] = [elo_role.get((pid, role), init) for pid, role in zip(cur['player_id'], cur['role'])]\n",
    "\n",
    "        maf_mask  = cur['team'].eq('mafia')\n",
    "        mafia_mu  = cur.loc[maf_mask, 'pre_elo'].mean()\n",
    "        citizen_mu= cur.loc[~maf_mask, 'pre_elo'].mean()\n",
    "        exp_mafia = 1.0 / (1.0 + 10 ** ((citizen_mu - mafia_mu)/400))\n",
    "        mafia_res = int(cur.loc[maf_mask, 'team_win'].iloc[0])\n",
    "\n",
    "        for _, r in cur.iterrows():\n",
    "            pid, side, role, rid = int(r['player_id']), r['team'], r['role'], int(r['id'])\n",
    "            gap = rid - last_seen.get(pid, rid)\n",
    "            decay = float(np.exp(-max(gap,0)/float(tau)))\n",
    "            exp = exp_mafia if side=='mafia' else (1-exp_mafia)\n",
    "            act = mafia_res if side=='mafia' else (1-mafia_res)\n",
    "            delta = k * decay * (act - exp)\n",
    "\n",
    "            elo_global[pid] = elo_global.get(pid,  init) + delta\n",
    "            elo_side[(pid, side)] = elo_side.get((pid, side), init) + delta\n",
    "            elo_role[(pid, role)] = elo_role.get((pid, role), init) + delta\n",
    "            last_seen[pid] = rid\n",
    "\n",
    "        outs.append(cur[['game_id','player_id','pre_elo','pre_elo_side','pre_elo_role']])\n",
    "\n",
    "    elo_df = pd.concat(outs, ignore_index=True)\n",
    "    return d.merge(elo_df, on=['game_id','player_id'], how='left')\n",
    "\n",
    "work_players = compute_elos(df, init=1500, k=24, tau=300.0)\n",
    "\n",
    "def add_rolling_stats_side(df, windows=(5,20)):\n",
    "    d = df.sort_values(['player_id','id']).copy()\n",
    "    for side in ['mafia','citizens']:\n",
    "        mask = d['team'].eq(side)\n",
    "        d.loc[mask, f'roll5_win_rate_{side}']  = d.loc[mask].groupby('player_id')['team_win'].shift(1).rolling(windows[0], min_periods=1).mean().values\n",
    "        d.loc[mask, f'roll20_win_rate_{side}'] = d.loc[mask].groupby('player_id')['team_win'].shift(1).rolling(windows[1], min_periods=1).mean().values\n",
    "        d.loc[~mask, f'roll5_win_rate_{side}']  = 0.0\n",
    "        d.loc[~mask, f'roll20_win_rate_{side}'] = 0.0\n",
    "    return d\n",
    "\n",
    "work_players = add_rolling_stats_side(work_players)\n",
    "\n",
    "def add_role_history_stats(df, windows=(5,20,50)):\n",
    "    d = df.sort_values(['player_id','role','id']).copy()\n",
    "    out = []\n",
    "    for (pid, role), g in d.groupby(['player_id','role'], sort=False):\n",
    "        g = g.copy()\n",
    "        past = g['team_win'].shift(1)\n",
    "        g['games_in_role'] = np.arange(len(g), dtype=np.int32)\n",
    "        for w in windows:\n",
    "            g[f'win_rate_role_{role}_last{w}'] = past.rolling(w, min_periods=1).mean()\n",
    "        out.append(g)\n",
    "    return pd.concat(out, ignore_index=True).sort_values('id').reset_index(drop=True)\n",
    "\n",
    "work_players = add_role_history_stats(work_players, windows=(5,20,50))\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "def add_synergy_features(df):\n",
    "    d = df.copy()\n",
    "    game_order = (d.groupby('game_id')['id'].max().sort_values().index.tolist())\n",
    "    pair_counts = {}\n",
    "    out_rows = []\n",
    "\n",
    "    for gid in game_order:\n",
    "        g = d[d['game_id'] == gid]\n",
    "        for team in ['mafia', 'citizens']:\n",
    "            players = g.loc[g['team']==team, 'player_id'].dropna().astype(int).tolist()\n",
    "            vals = [pair_counts.get((a,b,team), 0) for a,b in combinations(sorted(players), 2)] if len(players)>=2 else []\n",
    "            s_mean = float(np.mean(vals)) if vals else 0.0\n",
    "            s_max  = float(np.max(vals))  if vals else 0.0\n",
    "            out_rows.append((gid, team, s_mean, s_max))\n",
    "        # update after\n",
    "        for team in ['mafia', 'citizens']:\n",
    "            players = g.loc[g['team']==team, 'player_id'].dropna().astype(int).tolist()\n",
    "            if len(players)>=2:\n",
    "                for a,b in combinations(sorted(players), 2):\n",
    "                    pair_counts[(a,b,team)] = pair_counts.get((a,b,team),0) + 1\n",
    "\n",
    "    team_synergy = pd.DataFrame(out_rows, columns=['game_id','team','synergy_mean_team','synergy_max_team'])\n",
    "    return d.merge(team_synergy, on=['game_id','team'], how='left')\n",
    "\n",
    "work_players = add_synergy_features(work_players)\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "def add_enemy_familiarity_features(df):\n",
    "    d = df.sort_values('id').copy()\n",
    "    game_order = (d.groupby('game_id')['id'].max().sort_values().index.tolist())\n",
    "    faced_counts = {}\n",
    "    out_rows = []\n",
    "\n",
    "    for gid in game_order:\n",
    "        g = d[d['game_id'] == gid]\n",
    "        maf = g[g['team']=='mafia']['player_id'].dropna().astype(int).tolist()\n",
    "        cit = g[g['team']=='citizens']['player_id'].dropna().astype(int).tolist()\n",
    "\n",
    "        pairs_maf = [faced_counts.get(tuple(sorted([a,b])), 0) for a,b in product(maf, cit)]\n",
    "        pairs_cit = [faced_counts.get(tuple(sorted([a,b])), 0) for a,b in product(cit, maf)]\n",
    "\n",
    "        def stats(vals):\n",
    "            return (float(np.mean(vals)) if vals else 0.0,\n",
    "                    float(np.max(vals))  if vals else 0.0)\n",
    "\n",
    "        maf_mean, maf_max = stats(pairs_maf)\n",
    "        cit_mean, cit_max = stats(pairs_cit)\n",
    "\n",
    "        out_rows.append((gid,'mafia',    maf_mean, maf_max))\n",
    "        out_rows.append((gid,'citizens', cit_mean, cit_max))\n",
    "\n",
    "        for a,b in product(maf, cit):\n",
    "            key = tuple(sorted([int(a),int(b)]))\n",
    "            faced_counts[key] = faced_counts.get(key, 0) + 1\n",
    "\n",
    "    fam = pd.DataFrame(out_rows, columns=['game_id','team','enemy_fam_mean_team','enemy_fam_max_team'])\n",
    "    return d.merge(fam, on=['game_id','team'], how='left')\n",
    "\n",
    "work_players = add_enemy_familiarity_features(work_players)\n",
    "\n",
    "def add_streak_features(df):\n",
    "    d = df.sort_values(['player_id','id']).copy()\n",
    "    win_streaks, loss_streaks = [], []\n",
    "\n",
    "    for pid, g in d.groupby('player_id', sort=False):\n",
    "        prev = g['team_win'].shift(1).values\n",
    "        w_stk = np.zeros(len(g), dtype=np.int16)\n",
    "        l_stk = np.zeros(len(g), dtype=np.int16)\n",
    "        cur_w = cur_l = 0\n",
    "        for i, v in enumerate(prev):\n",
    "            if np.isnan(v):\n",
    "                cur_w = cur_l = 0\n",
    "            else:\n",
    "                if v == 1:\n",
    "                    cur_w += 1; cur_l = 0\n",
    "                else:\n",
    "                    cur_l += 1; cur_w = 0\n",
    "            w_stk[i] = cur_w\n",
    "            l_stk[i] = cur_l\n",
    "        win_streaks.append(pd.Series(w_stk, index=g.index))\n",
    "        loss_streaks.append(pd.Series(l_stk, index=g.index))\n",
    "\n",
    "    d['win_streak']  = pd.concat(win_streaks).sort_index()\n",
    "    d['loss_streak'] = pd.concat(loss_streaks).sort_index()\n",
    "    return d.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "work_players = add_streak_features(work_players)\n",
    "\n",
    "def add_games_played_feature(df):\n",
    "    d = df.sort_values(['player_id','id']).copy()\n",
    "    # number of *prior* appearances (shift to avoid leakage)\n",
    "    d['games_played'] = d.groupby('player_id').cumcount().astype('int32')\n",
    "    return d.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "work_players = add_games_played_feature(work_players)\n",
    "\n",
    "def build_team_agg(work_players, add_ratios=False, ratio_eps=1e-3):\n",
    "    agg_funcs = {}\n",
    "\n",
    "    def add_agg(col, funcs):\n",
    "        if col in work_players.columns:\n",
    "            agg_funcs[col] = funcs\n",
    "\n",
    "    def q25(x): return np.nanpercentile(x, 25)\n",
    "    def q75(x): return np.nanpercentile(x, 75)\n",
    "\n",
    "    # Core\n",
    "    add_agg('pre_elo', ['mean','std','min','max', q25, q75])\n",
    "    add_agg('pre_elo_side', ['mean'])\n",
    "    add_agg('pre_elo_role', ['mean'])\n",
    "    add_agg('gap_id_clipped', ['mean','max'])\n",
    "    add_agg('long_break_flag', ['sum'])\n",
    "    add_agg('place', ['mean','std','min','max'])\n",
    "    add_agg('games_played', ['mean','std','min','max'])  # if present\n",
    "\n",
    "    # Optional blocks\n",
    "    add_agg('win_streak', ['mean','max'])\n",
    "    add_agg('loss_streak', ['mean','max'])\n",
    "    add_agg('synergy_mean_team', ['mean'])\n",
    "    add_agg('synergy_max_team',  ['mean'])\n",
    "    add_agg('enemy_fam_mean_team', ['mean'])\n",
    "    add_agg('enemy_fam_max_team',  ['mean'])\n",
    "    add_agg('roll5_win_rate_mafia',  ['mean'])\n",
    "    add_agg('roll20_win_rate_mafia', ['mean'])\n",
    "    add_agg('roll5_win_rate_citizens',  ['mean'])\n",
    "    add_agg('roll20_win_rate_citizens', ['mean'])\n",
    "    if 'meta_period' in work_players.columns:\n",
    "        agg_funcs['meta_period'] = ['first']\n",
    "\n",
    "    base = work_players.groupby(['game_id','team']).agg(agg_funcs)\n",
    "    base.columns = ['_'.join([str(x) for x in c if x not in (None,)]).replace('<function ','').replace('>','')\n",
    "                    for c in base.columns]\n",
    "    base = base.reset_index()\n",
    "\n",
    "    # --- NEW: meta-period normalization for Elo stats (remove era drift) ---\n",
    "    if 'meta_period_first' in base.columns:\n",
    "        elo_cols = [c for c in base.columns if c.startswith('pre_elo_')]\n",
    "        for col in elo_cols:\n",
    "            # center within meta-period\n",
    "            base[f'{col}_norm'] = base[col] - base.groupby('meta_period_first')[col].transform('mean')\n",
    "\n",
    "    # Role-specific singletons/means\n",
    "    full_idx = base.set_index(['game_id','team']).index\n",
    "    # Role-specific singletons/means\n",
    "    full_idx = base.set_index(['game_id','team']).index\n",
    "\n",
    "    def single_role_stat(role, value_col, out_name):\n",
    "        s = (work_players[work_players['role']==role]\n",
    "             .groupby(['game_id','team'])[value_col].mean()).reindex(full_idx)\n",
    "        s.name = out_name; return s\n",
    "\n",
    "    def mean_role_stat(role, value_col, out_name):\n",
    "        s = (work_players[work_players['role']==role]\n",
    "             .groupby(['game_id','team'])[value_col].mean()).reindex(full_idx)\n",
    "        s.name = out_name; return s\n",
    "\n",
    "    pieces = [\n",
    "        single_role_stat('don','pre_elo_role','don_pre_elo_role'),\n",
    "        single_role_stat('sheriff','pre_elo_role','sheriff_pre_elo_role'),\n",
    "        single_role_stat('don','place','don_place'),\n",
    "        single_role_stat('sheriff','place','sheriff_place'),\n",
    "        mean_role_stat('black','pre_elo_role','black_mean_pre_elo_role'),\n",
    "        mean_role_stat('red','pre_elo_role','red_mean_pre_elo_role'),\n",
    "        single_role_stat('don','games_in_role','don_games_in_role'),\n",
    "        single_role_stat('sheriff','games_in_role','sheriff_games_in_role'),\n",
    "        mean_role_stat('black','games_in_role','black_mean_games_in_role'),\n",
    "        mean_role_stat('red','games_in_role','red_mean_games_in_role'),\n",
    "        single_role_stat('don','win_rate_role_don_last20','don_wr20'),\n",
    "        single_role_stat('sheriff','win_rate_role_sheriff_last20','sheriff_wr20'),\n",
    "        mean_role_stat('black','win_rate_role_black_last20','black_mean_wr20'),\n",
    "        mean_role_stat('red','win_rate_role_red_last20','red_mean_wr20'),\n",
    "    ]\n",
    "    role_feats = pd.concat(pieces, axis=1).reset_index()\n",
    "    team_agg = base.merge(role_feats, on=['game_id','team'], how='left')\n",
    "\n",
    "    # Label & time proxy\n",
    "    labels  = work_players.groupby(['game_id','team'])['team_win'].max().rename('team_win_team')\n",
    "    gmaxid  = work_players.groupby('game_id')['id'].max().rename('game_max_id')\n",
    "    team_agg = team_agg.merge(labels, on=['game_id','team']).merge(gmaxid, on='game_id')\n",
    "\n",
    "    # Safe deltas / ratios\n",
    "    wide = team_agg.pivot(index='game_id', columns='team')\n",
    "    wide.columns = [f\"{a}__{b}\" for a,b in wide.columns]\n",
    "    wide = wide.reset_index()\n",
    "\n",
    "    def side_cols(side): \n",
    "        return [c for c in wide.columns if c.endswith(f\"__{side}\") and c!='game_id']\n",
    "    maf_cols = side_cols('mafia')\n",
    "\n",
    "    delta = pd.DataFrame({'game_id': wide['game_id']})\n",
    "    skip_prefixes = ('team_win_team','meta_period')\n",
    "    for mcol in maf_cols:\n",
    "        base_name = mcol[:-len(\"__mafia\")]\n",
    "        if base_name.startswith(skip_prefixes): \n",
    "            continue\n",
    "        ccol = base_name + \"__citizens\"\n",
    "        if ccol in wide.columns:\n",
    "            delta[base_name + \"__delta_maf_minus_cit\"] = wide[mcol] - wide[ccol]\n",
    "            if add_ratios:\n",
    "                delta[base_name + \"__ratio_maf_over_cit\"] = (wide[mcol] + ratio_eps) / (wide[ccol] + ratio_eps)\n",
    "\n",
    "    team_tall = team_agg.merge(delta, on='game_id', how='left')\n",
    "\n",
    "    # --- NEW: a few safe interactions (helps tree models separate regimes) ---\n",
    "    def safe_mul(a, b): \n",
    "        return (team_tall.get(a) if a in team_tall else 0) * (team_tall.get(b) if b in team_tall else 0)\n",
    "\n",
    "    def safe_diff(a, b): \n",
    "        return (team_tall.get(a) if a in team_tall else 0) - (team_tall.get(b) if b in team_tall else 0)\n",
    "\n",
    "    # Names used below exist after delta creation; if any is missing in your run, it's treated as 0\n",
    "    team_tall['elo_synergy_product'] = safe_mul('pre_elo_mean__delta_maf_minus_cit',\n",
    "                                                'synergy_mean_team_mean__delta_maf_minus_cit')\n",
    "    team_tall['elo_enemy_gap']       = safe_diff('pre_elo_mean__delta_maf_minus_cit',\n",
    "                                                'enemy_fam_mean_team_mean__delta_maf_minus_cit')\n",
    "    team_tall['elo_streak_mix']      = safe_mul('pre_elo_mean__delta_maf_minus_cit',\n",
    "                                                'win_streak_mean__delta_maf_minus_cit')\n",
    "\n",
    "    return team_tall\n",
    "\n",
    "team_tall = build_team_agg(work_players, add_ratios=False)  # ratios often redundant\n",
    "\n",
    "team_only = [c for c in team_tall.columns if c.startswith((\n",
    "    'pre_elo_', 'gap_id_clipped_', 'long_break_flag_', 'place_',\n",
    "    'win_streak_', 'loss_streak_', 'synergy_mean_team_', 'synergy_max_team_',\n",
    "    'enemy_fam_', 'games_played_', \n",
    "    'don_pre_elo_role', 'sheriff_pre_elo_role', 'black_mean_pre_elo_role', 'red_mean_pre_elo_role',\n",
    "    'don_games_in_role', 'sheriff_games_in_role', 'black_mean_games_in_role', 'red_mean_games_in_role',\n",
    "    'don_wr20', 'sheriff_wr20', 'black_mean_wr20', 'red_mean_wr20',\n",
    "    'meta_period_first'\n",
    "))]\n",
    "delta_feats = [c for c in team_tall.columns if c.endswith('__delta_maf_minus_cit')]\n",
    "\n",
    "# NEW: explicitly add our interactions and meta-normalized Elo columns\n",
    "extra_feats = [c for c in ['elo_synergy_product','elo_enemy_gap','elo_streak_mix']\n",
    "               if c in team_tall.columns]\n",
    "meta_norm_feats = [c for c in team_tall.columns if c.endswith('_norm')]\n",
    "\n",
    "forbidden_tokens = {'team_win','team_win_team'}\n",
    "USED_FEATS = [c for c in sorted(set(team_only + delta_feats + extra_feats + meta_norm_feats))\n",
    "              if not any(tok in c for tok in forbidden_tokens)]\n",
    "\n",
    "X = team_tall[USED_FEATS].fillna(0)\n",
    "y = team_tall['team_win_team'].astype(int).values\n",
    "groups = team_tall['game_id'].values\n",
    "time_key = team_tall['game_max_id'].values\n",
    "\n",
    "q70, q85 = np.quantile(time_key, [0.70, 0.85])\n",
    "train_mask = time_key <= q85\n",
    "cal_mask   = (time_key > q70) & (time_key <= q85)\n",
    "test_mask  = time_key > q85\n",
    "\n",
    "print(\"Shapes | X:\", X.shape, \"| y:\", y.shape)\n",
    "print(\"Split sizes | train:\", train_mask.sum(), \"cal:\", cal_mask.sum(), \"test:\", test_mask.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0491581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 116007, 'cal': 20472, 'fit': 136479, 'inner_tr': 98606, 'inner_va': 17401, 'test': 24085}\n",
      "Check shapes: train (116007, 105) cal (20472, 105) inner_tr (98606, 105) inner_va (17401, 105) holdout (24085, 105)\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 3) Canonical splits (train / cal / holdout)\n",
    "# ==============================\n",
    "n = len(y)\n",
    "n_holdout = int(round(n * 0.15))\n",
    "idx_all = np.arange(n)\n",
    "\n",
    "# Holdout: last 15%\n",
    "idx_holdout = idx_all[-n_holdout:]\n",
    "idx_fitpool = idx_all[:-n_holdout]\n",
    "\n",
    "# Calibration: 15% of fit pool (from the tail of fit pool)\n",
    "n_cal = int(round(len(idx_fitpool) * 0.15))\n",
    "idx_cal = idx_fitpool[-n_cal:]\n",
    "idx_train = idx_fitpool[:-n_cal]\n",
    "\n",
    "# Inner split for LGBM early stopping (from train)\n",
    "n_va = int(round(len(idx_train) * 0.15))\n",
    "idx_inner_va = idx_train[-n_va:]\n",
    "idx_inner_tr = idx_train[:-n_va]\n",
    "\n",
    "sizes = {\n",
    "    \"train\": len(idx_train),\n",
    "    \"cal\": len(idx_cal),\n",
    "    \"fit\": len(idx_fitpool),\n",
    "    \"inner_tr\": len(idx_inner_tr),\n",
    "    \"inner_va\": len(idx_inner_va),\n",
    "    \"test\": len(idx_holdout),\n",
    "}\n",
    "print(sizes)\n",
    "\n",
    "# Slice arrays (keep as DataFrames/Series)\n",
    "def _slice_xy(X, y, idx):\n",
    "    Xs = X.iloc[idx] if hasattr(X, \"iloc\") else pd.DataFrame(X)[idx]\n",
    "    ys = y.iloc[idx] if hasattr(y, \"iloc\") else pd.Series(y)[idx]\n",
    "    return Xs.reset_index(drop=True), ys.reset_index(drop=True)\n",
    "\n",
    "X_train, y_train   = _slice_xy(X, y, idx_train)\n",
    "X_cal,   y_cal     = _slice_xy(X, y, idx_cal)\n",
    "X_inner_tr, y_inner_tr = _slice_xy(X, y, idx_inner_tr)\n",
    "X_inner_va, y_inner_va = _slice_xy(X, y, idx_inner_va)\n",
    "X_holdout, y_holdout   = _slice_xy(X, y, idx_holdout)\n",
    "\n",
    "print(\"Check shapes:\",\n",
    "      \"train\", X_train.shape, \n",
    "      \"cal\", X_cal.shape,\n",
    "      \"inner_tr\", X_inner_tr.shape,\n",
    "      \"inner_va\", X_inner_va.shape,\n",
    "      \"holdout\", X_holdout.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a52ab4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt',\n",
      " 'colsample_bytree': 0.7844939514101106,\n",
      " 'learning_rate': 0.02,\n",
      " 'min_data_in_leaf': 134,\n",
      " 'n_estimators': 5000,\n",
      " 'n_jobs': -1,\n",
      " 'num_leaves': 78,\n",
      " 'objective': 'binary',\n",
      " 'random_state': 42,\n",
      " 'reg_alpha': 0.5453556057858624,\n",
      " 'reg_lambda': 0.1904075276204348,\n",
      " 'subsample': 0.8140936140036887}\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Info] Number of positive: 49303, number of negative: 49303\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15051\n",
      "[LightGBM] [Info] Number of data points in the train set: 98606, number of used features: 88\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's binary_logloss: 0.658859\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's binary_logloss: 0.658613\n",
      "LGBM fitted with best_iteration_ = 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\George\\anaconda3\\envs\\mafia_analysis\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=134, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=134\n",
      "\n",
      "LGBM (calibrated) — Holdout\n",
      "LogLoss: 0.6665559744\n",
      "AUC: 0.6297505701\n",
      "Brier: 0.2370229242\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 4) LightGBM — train + calibrate + evaluate\n",
    "# ==============================\n",
    "lgb_params_tuned = {\n",
    "    \"n_estimators\": 5000,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"num_leaves\": 78,\n",
    "    \"min_data_in_leaf\": 134,\n",
    "    \"subsample\": 0.8140936140036887,\n",
    "    \"colsample_bytree\": 0.7844939514101106,\n",
    "    \"reg_lambda\": 0.1904075276204348,\n",
    "    \"reg_alpha\": 0.5453556057858624,\n",
    "    \"objective\": \"binary\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": SEED,\n",
    "}\n",
    "pprint(lgb_params_tuned)\n",
    "\n",
    "# Train with early stopping on inner_va\n",
    "lgb = LGBMClassifier(**lgb_params_tuned)\n",
    "lgb.fit(\n",
    "    X_inner_tr, y_inner_tr,\n",
    "    eval_set=[(X_inner_va, y_inner_va)],\n",
    "    eval_metric=\"logloss\",\n",
    "    callbacks=[early_stopping(stopping_rounds=100), log_evaluation(200)]\n",
    ")\n",
    "print(\"LGBM fitted with best_iteration_ =\", getattr(lgb, \"best_iteration_\", None))\n",
    "\n",
    "# Calibrate on calibration set\n",
    "lgb_cal = CalibratedClassifierCV(lgb, cv=\"prefit\", method=\"sigmoid\")\n",
    "lgb_cal.fit(X_cal, y_cal)\n",
    "\n",
    "# Evaluate on holdout\n",
    "p_lgb = lgb_cal.predict_proba(X_holdout)[:, 1]\n",
    "metrics_lgb = {\n",
    "    \"LogLoss\": log_loss(y_holdout, p_lgb),\n",
    "    \"AUC\": roc_auc_score(y_holdout, p_lgb),\n",
    "    \"Brier\": brier_score_loss(y_holdout, p_lgb),\n",
    "}\n",
    "print(\"\\nLGBM (calibrated) — Holdout\")\n",
    "for k,v in metrics_lgb.items():\n",
    "    print(f\"{k}: {v:.10f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d393dc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6919197\ttest: 0.6917088\tbest: 0.6917088 (0)\ttotal: 327ms\tremaining: 10m 53s\n",
      "200:\tlearn: 0.6582651\ttest: 0.6522251\tbest: 0.6522251 (200)\ttotal: 32.3s\tremaining: 4m 49s\n",
      "400:\tlearn: 0.6483437\ttest: 0.6432742\tbest: 0.6432742 (400)\ttotal: 1m 3s\tremaining: 4m 14s\n",
      "600:\tlearn: 0.6364242\ttest: 0.6316679\tbest: 0.6316679 (600)\ttotal: 1m 34s\tremaining: 3m 39s\n",
      "800:\tlearn: 0.6256300\ttest: 0.6219296\tbest: 0.6219296 (800)\ttotal: 2m 4s\tremaining: 3m 5s\n",
      "1000:\tlearn: 0.6151933\ttest: 0.6123993\tbest: 0.6123993 (1000)\ttotal: 2m 33s\tremaining: 2m 33s\n",
      "1200:\tlearn: 0.6048901\ttest: 0.6029702\tbest: 0.6029702 (1200)\ttotal: 3m 3s\tremaining: 2m 2s\n",
      "1400:\tlearn: 0.5947692\ttest: 0.5939215\tbest: 0.5939215 (1400)\ttotal: 3m 33s\tremaining: 1m 31s\n",
      "1600:\tlearn: 0.5854162\ttest: 0.5851037\tbest: 0.5851037 (1600)\ttotal: 4m 3s\tremaining: 1m\n",
      "1800:\tlearn: 0.5764603\ttest: 0.5768919\tbest: 0.5768919 (1800)\ttotal: 4m 34s\tremaining: 30.4s\n",
      "1999:\tlearn: 0.5673948\ttest: 0.5684793\tbest: 0.5684793 (1999)\ttotal: 5m 5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5684792558\n",
      "bestIteration = 1999\n",
      "\n",
      "CatBoost fitted.\n",
      "\n",
      "CatBoost (calibrated) — Holdout\n",
      "LogLoss: 0.6670964744\n",
      "AUC: 0.6288397346\n",
      "Brier: 0.2372824973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\George\\anaconda3\\envs\\mafia_analysis\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 5) CatBoost — baseline (train + calibrate + evaluate)\n",
    "# ==============================\n",
    "cat_params = dict(\n",
    "    loss_function=\"Logloss\",\n",
    "    depth=8,\n",
    "    learning_rate=0.03,\n",
    "    iterations=2000,\n",
    "    random_seed=SEED,\n",
    "    eval_metric=\"Logloss\",\n",
    "    verbose=200,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=100,\n",
    "    subsample=1.0,\n",
    "    l2_leaf_reg=7.0,\n",
    "    bagging_temperature=1.0,\n",
    ")\n",
    "\n",
    "cat = CatBoostClassifier(**cat_params)\n",
    "cat.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_inner_va, y_inner_va),\n",
    "    use_best_model=True,\n",
    "    verbose=200\n",
    ")\n",
    "print(\"CatBoost fitted.\")\n",
    "\n",
    "# Calibrate on the same calibration set\n",
    "cat_cal = CalibratedClassifierCV(cat, cv=\"prefit\", method=\"sigmoid\")\n",
    "cat_cal.fit(X_cal, y_cal)\n",
    "\n",
    "# Evaluate on holdout\n",
    "p_cat = cat_cal.predict_proba(X_holdout)[:, 1]\n",
    "metrics_cat = {\n",
    "    \"LogLoss\": log_loss(y_holdout, p_cat),\n",
    "    \"AUC\": roc_auc_score(y_holdout, p_cat),\n",
    "    \"Brier\": brier_score_loss(y_holdout, p_cat),\n",
    "}\n",
    "print(\"\\nCatBoost (calibrated) — Holdout\")\n",
    "for k,v in metrics_cat.items():\n",
    "    print(f\"{k}: {v:.10f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7152ad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LGBM  : LogLoss=0.666556  AUC=0.629751  Brier=0.237023\n",
      "Cat   : LogLoss=0.667096  AUC=0.628840  Brier=0.237282\n",
      "\n",
      "Best blend (LGBM vs Cat): w_lgbm=0.58, w_cat=0.42\n",
      "→ LogLoss=0.665779  AUC=0.631850  Brier=0.236652\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 6) Blend search (LGBM vs Cat baseline)\n",
    "# ==============================\n",
    "def eval_metrics(y, p):\n",
    "    return (\n",
    "        log_loss(y, p),\n",
    "        roc_auc_score(y, p),\n",
    "        brier_score_loss(y, p),\n",
    "    )\n",
    "\n",
    "ll_lgb, auc_lgb, br_lgb = eval_metrics(y_holdout, p_lgb)\n",
    "ll_cat, auc_cat, br_cat = eval_metrics(y_holdout, p_cat)\n",
    "\n",
    "print(f\"\\nLGBM  : LogLoss={ll_lgb:.6f}  AUC={auc_lgb:.6f}  Brier={br_lgb:.6f}\")\n",
    "print(f\"Cat   : LogLoss={ll_cat:.6f}  AUC={auc_cat:.6f}  Brier={br_cat:.6f}\")\n",
    "\n",
    "ws = np.linspace(0.0, 1.0, 41)  # 0.00..1.00 step 0.025\n",
    "best = None\n",
    "for w in ws:\n",
    "    p_blend = w * p_lgb + (1 - w) * p_cat\n",
    "    ll, auc, br = eval_metrics(y_holdout, p_blend)\n",
    "    if best is None or ll < best[0]:\n",
    "        best = (ll, auc, br, w)\n",
    "\n",
    "ll_b, auc_b, br_b, w_star = best\n",
    "print(f\"\\nBest blend (LGBM vs Cat): w_lgbm={w_star:.2f}, w_cat={1-w_star:.2f}\")\n",
    "print(f\"→ LogLoss={ll_b:.6f}  AUC={auc_b:.6f}  Brier={br_b:.6f}\")\n",
    "\n",
    "p_blend = w_star * p_lgb + (1 - w_star) * p_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc0dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 7) Optional: CatBoost tuning (GridSearchCV)\n",
    "# ==============================\n",
    "RUN_CAT_TUNE = False  # flip to True if you want to tune\n",
    "\n",
    "if RUN_CAT_TUNE:\n",
    "    grid = {\n",
    "        \"depth\": [6, 8],\n",
    "        \"learning_rate\": [0.02, 0.03],\n",
    "        \"iterations\": [1500, 2000],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"l2_leaf_reg\": [3, 7],\n",
    "        \"bagging_temperature\": [0.5, 1.0],\n",
    "    }\n",
    "    base = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        random_seed=SEED,\n",
    "        eval_metric=\"Logloss\",\n",
    "        verbose=False\n",
    "    )\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "    gs = GridSearchCV(\n",
    "        estimator=base,\n",
    "        param_grid=grid,\n",
    "        scoring=\"neg_log_loss\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"[Cat tune] Fitting grid...\")\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"\\n[Cat tune] Best params:\", gs.best_params_)\n",
    "    print(\"[Cat tune] CV LogLoss:\", -gs.best_score_)\n",
    "\n",
    "    # Refit best on full train (X_train,y_train) with eval on inner_va for OD\n",
    "    best_params = dict(gs.best_params_)\n",
    "    best_params.update(dict(loss_function=\"Logloss\", random_seed=SEED, eval_metric=\"Logloss\", verbose=200,\n",
    "                            od_type=\"Iter\", od_wait=100))\n",
    "    cat_tuned = CatBoostClassifier(**best_params)\n",
    "    cat_tuned.fit(X_train, y_train, eval_set=(X_inner_va, y_inner_va), use_best_model=True, verbose=200)\n",
    "\n",
    "    # Calibrate on calibration set\n",
    "    cat_tuned_cal = CalibratedClassifierCV(cat_tuned, cv=\"prefit\", method=\"sigmoid\")\n",
    "    cat_tuned_cal.fit(X_cal, y_cal)\n",
    "\n",
    "    # Predict on holdout (same length as y_holdout)\n",
    "    p_cat_tuned = cat_tuned_cal.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "    ll_t, auc_t, br_t = eval_metrics(y_holdout, p_cat_tuned)\n",
    "    print(f\"\\n[Cat tune] Tuned Cat — Holdout  LogLoss={ll_t:.6f}  AUC={auc_t:.6f}  Brier={br_t:.6f}\")\n",
    "\n",
    "    # Blend LGBM with tuned Cat\n",
    "    best_t = None\n",
    "    for w in ws:\n",
    "        p = w * p_lgb + (1 - w) * p_cat_tuned\n",
    "        ll, auc, br = eval_metrics(y_holdout, p)\n",
    "        if best_t is None or ll < best_t[0]:\n",
    "            best_t = (ll, auc, br, w)\n",
    "    ll_bt, auc_bt, br_bt, w_star_t = best_t\n",
    "    print(f\"\\nBest blend (LGBM vs CatTuned): w_lgbm={w_star_t:.2f}, w_catT={1-w_star_t:.2f}\")\n",
    "    print(f\"→ LogLoss={ll_bt:.6f}  AUC={auc_bt:.6f}  Brier={br_bt:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b481c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 threshold (holdout): 0.35, F1=0.6712\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 8) F1 threshold search (diagnostic)\n",
    "# ==============================\n",
    "# Use the best currently available prediction (blend if it improved LogLoss; else Cat or LGBM)\n",
    "p_best = p_blend if 'p_blend' in globals() else (p_cat if metrics_cat['LogLoss'] <= metrics_lgb['LogLoss'] else p_lgb)\n",
    "\n",
    "ths = np.linspace(0.05, 0.95, 19)\n",
    "best_f1, best_t = -1, None\n",
    "for t in ths:\n",
    "    f1 = f1_score(y_holdout, (p_best >= t).astype(int))\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_t = f1, t\n",
    "print(f\"Best F1 threshold (holdout): {best_t:.2f}, F1={best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb708ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features (LGBM):\n",
      "roll20_win_rate_citizens_mean__delta_maf_minus_cit    1752\n",
      "roll5_win_rate_citizens_mean__delta_maf_minus_cit     1086\n",
      "gap_id_clipped_mean                                    630\n",
      "pre_elo_side_mean__delta_maf_minus_cit                 584\n",
      "gap_id_clipped_max                                     581\n",
      "roll20_win_rate_mafia_mean__delta_maf_minus_cit        553\n",
      "gap_id_clipped_mean__delta_maf_minus_cit               464\n",
      "pre_elo_min__delta_maf_minus_cit                       452\n",
      "pre_elo_q25__delta_maf_minus_cit                       426\n",
      "pre_elo_role_mean__delta_maf_minus_cit                 390\n",
      "elo_synergy_product                                    382\n",
      "pre_elo_side_mean                                      373\n",
      "enemy_fam_mean_team_mean                               367\n",
      "elo_streak_mix                                         348\n",
      "place_std                                              333\n",
      "roll5_win_rate_mafia_mean__delta_maf_minus_cit         317\n",
      "synergy_mean_team_mean__delta_maf_minus_cit            307\n",
      "place_mean                                             305\n",
      "pre_elo_max__delta_maf_minus_cit                       302\n",
      "pre_elo_side_mean_norm                                 301\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 9) Feature importances (LightGBM)\n",
    "# ==============================\n",
    "if hasattr(lgb, \"feature_importances_\"):\n",
    "    fi = pd.Series(lgb.feature_importances_, index=X_inner_tr.columns).sort_values(ascending=False)\n",
    "    topk = fi.head(20)\n",
    "    print(\"Top 20 features (LGBM):\")\n",
    "    print(topk)\n",
    "else:\n",
    "    print(\"LightGBM importances not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bca16690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   LogLoss          AUC        Brier\n",
      "Model                                                               \n",
      "LGBM (calibrated)             0.6665559744 0.6297505701 0.2370229242\n",
      "CatBoost (calibrated)         0.6670964744 0.6288397346 0.2372824973\n",
      "Blend* (0.58·LGBM + 0.42·Cat) 0.6657793963 0.6318499647 0.2366521003\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 10) Final summary table\n",
    "# ==============================\n",
    "rows = []\n",
    "\n",
    "rows.append({\n",
    "    \"Model\": \"LGBM (calibrated)\",\n",
    "    \"LogLoss\": metrics_lgb[\"LogLoss\"],\n",
    "    \"AUC\":     metrics_lgb[\"AUC\"],\n",
    "    \"Brier\":   metrics_lgb[\"Brier\"],\n",
    "})\n",
    "\n",
    "rows.append({\n",
    "    \"Model\": \"CatBoost (calibrated)\",\n",
    "    \"LogLoss\": metrics_cat[\"LogLoss\"],\n",
    "    \"AUC\":     metrics_cat[\"AUC\"],\n",
    "    \"Brier\":   metrics_cat[\"Brier\"],\n",
    "})\n",
    "\n",
    "if 'p_blend' in globals():\n",
    "    rows.append({\n",
    "        \"Model\": f\"Blend* ({w_star:.2f}·LGBM + {(1-w_star):.2f}·Cat)\",\n",
    "        \"LogLoss\": ll_b,\n",
    "        \"AUC\":     auc_b,\n",
    "        \"Brier\":   br_b,\n",
    "    })\n",
    "\n",
    "if 'RUN_CAT_TUNE' in globals() and RUN_CAT_TUNE and 'p_cat_tuned' in globals():\n",
    "    # tuned cat\n",
    "    rows.append({\n",
    "        \"Model\": \"CatBoost (tuned + cal)\",\n",
    "        \"LogLoss\": ll_t,\n",
    "        \"AUC\":     auc_t,\n",
    "        \"Brier\":   br_t,\n",
    "    })\n",
    "    # tuned blend\n",
    "    rows.append({\n",
    "        \"Model\": f\"Blend** ({w_star_t:.2f}·LGBM + {(1-w_star_t):.2f}·CatT)\",\n",
    "        \"LogLoss\": ll_bt,\n",
    "        \"AUC\":     auc_bt,\n",
    "        \"Brier\":   br_bt,\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(rows).set_index(\"Model\")\n",
    "\n",
    "# Pretty print without requiring jinja2\n",
    "def _fmt(x): \n",
    "    try: \n",
    "        return f\"{x:.10f}\"\n",
    "    except: \n",
    "        return x\n",
    "\n",
    "print(summary.to_string(float_format=lambda x: f\"{x:.10f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec45bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor ready.\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 11) Export predictor function (optional)\n",
    "# ==============================\n",
    "def make_predict_proba_fn(model=\"blend\"):\n",
    "    \"\"\"\n",
    "    Returns a function f(X_df) -> proba for chosen model:\n",
    "    - \"lgbm\": calibrated LightGBM\n",
    "    - \"cat\": calibrated CatBoost\n",
    "    - \"blend\": best 2-way blend found on holdout (if available; else falls back to better single model)\n",
    "    \"\"\"\n",
    "    if model == \"lgbm\":\n",
    "        def f(X_df):\n",
    "            return lgb_cal.predict_proba(X_df)[:, 1]\n",
    "        return f\n",
    "    elif model == \"cat\":\n",
    "        def f(X_df):\n",
    "            return cat_cal.predict_proba(X_df)[:, 1]\n",
    "        return f\n",
    "    elif model == \"blend\":\n",
    "        if 'p_blend' in globals():\n",
    "            w = w_star\n",
    "            def f(X_df):\n",
    "                p1 = lgb_cal.predict_proba(X_df)[:, 1]\n",
    "                p2 = cat_cal.predict_proba(X_df)[:, 1]\n",
    "                return w * p1 + (1 - w) * p2\n",
    "            return f\n",
    "        else:\n",
    "            # choose better single by LogLoss\n",
    "            if metrics_cat[\"LogLoss\"] <= metrics_lgb[\"LogLoss\"]:\n",
    "                return make_predict_proba_fn(\"cat\")\n",
    "            else:\n",
    "                return make_predict_proba_fn(\"lgbm\")\n",
    "    else:\n",
    "        raise ValueError(\"model must be one of {'lgbm','cat','blend'}\")\n",
    "\n",
    "predict_proba = make_predict_proba_fn(\"blend\")\n",
    "print(\"Predictor ready.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mafia_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
