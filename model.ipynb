{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e06612",
   "metadata": {},
   "source": [
    "# Mafia — Per-Game Outcome Modeling (Pre-Game Only)\n",
    "\n",
    "Goal: predict the **winning side** (mafia vs citizens) from the lineup and past form.\n",
    "- Label per team row: `team_win_team` (1/0)\n",
    "- Validation: GroupKFold by `game_id` + chronological holdout by `game_max_id`\n",
    "- Metrics: LogLoss (primary), ROC-AUC, Brier, per-game accuracy\n",
    "- Features: per-player Elo & rolling stats → aggregated to team → deltas (mafia - citizens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1978a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy lightgbm scikit-learn pyarrow fastparquet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "DATA_PLAYERS = Path(\"cleaned/mafia_clean.csv\")  # cleaned player-level dataset\n",
    "OUT_DIR = Path(\"./team_data\"); OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "ARTS = Path(\"./artifacts_game\"); ARTS.mkdir(exist_ok=True, parents=True)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c8c49",
   "metadata": {},
   "source": [
    "## 1) Load cleaned player-level data\n",
    "We expect: 10 rows per game, 3 mafia / 7 citizens, winners per game ∈ {3,7}, no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65fdb7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\George\\AppData\\Local\\Temp\\ipykernel_18400\\3333621096.py:1: DtypeWarning: Columns (16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(DATA_PLAYERS)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((802820, 21),\n",
       "         id  game_id  place  player_id original_nickname   role  killed_first  \\\n",
       " 0  1000001   100001     10          2             Teddy    red             0   \n",
       " 1  1000002   100001      7         26          Искатель    red             0   \n",
       " 2  1000003   100001      9         50             Лоску  black             0   \n",
       " \n",
       "    best_move  game_points  game_autobonus  ...  best_move_bonus  penalty  \\\n",
       " 0          0          0.0             0.0  ...              0.0      0.0   \n",
       " 1          0          0.0             0.0  ...              0.0      0.0   \n",
       " 2          0          2.0             0.0  ...              0.0      0.0   \n",
       " \n",
       "    fouls  penalty_disciplinary   Ci  created_at updated_at      team team_win  \\\n",
       " 0    0.0                   0.0  0.0         NaN        NaN  citizens        0   \n",
       " 1    0.0                   0.0  0.0         NaN        NaN  citizens        0   \n",
       " 2    0.0                   0.0  0.0         NaN        NaN     mafia        1   \n",
       " \n",
       "    total_points  \n",
       " 0           0.0  \n",
       " 1           0.0  \n",
       " 2           2.0  \n",
       " \n",
       " [3 rows x 21 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PLAYERS)\n",
    "df.shape, df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6bc5da",
   "metadata": {},
   "source": [
    "## 2) Pre-game player features: Elo + rolling stats (leakage-safe)\n",
    "- Sort by `id` (time proxy).\n",
    "- Elo updates only from past results.\n",
    "- Rolling win rate (5, 20), career win rate, games played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01b8803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    732003.000000\n",
      "mean        135.976756\n",
      "std        1368.720034\n",
      "min           1.000000\n",
      "50%          42.000000\n",
      "80%         127.000000\n",
      "90%         228.000000\n",
      "95%         381.000000\n",
      "99%        1174.000000\n",
      "max      245724.000000\n",
      "Name: id, dtype: float64\n",
      "Chosen GAP_THRESH (id units): 381.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect distribution of per-player id gaps\n",
    "tmp = (df.sort_values(['player_id','id'])\n",
    "         .groupby('player_id')['id']\n",
    "         .diff()\n",
    "         .dropna())\n",
    "print(tmp.describe(percentiles=[.5,.8,.9,.95,.99]))\n",
    "\n",
    "# Choose a threshold (start with the 95th percentile as a proxy)\n",
    "GAP_THRESH = tmp.quantile(0.95)\n",
    "print(\"Chosen GAP_THRESH (id units):\", GAP_THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef833f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team</th>\n",
       "      <th>player_id</th>\n",
       "      <th>pre_elo</th>\n",
       "      <th>roll5_win_rate</th>\n",
       "      <th>roll20_win_rate</th>\n",
       "      <th>career_win_rate</th>\n",
       "      <th>games_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>2</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>26</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>50</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>74</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>98</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id      team  player_id  pre_elo  roll5_win_rate  roll20_win_rate  \\\n",
       "0   100001  citizens          2   1500.0             NaN              NaN   \n",
       "1   100001  citizens         26   1500.0             NaN              NaN   \n",
       "2   100001     mafia         50   1500.0             NaN              NaN   \n",
       "3   100001     mafia         74   1500.0             NaN              NaN   \n",
       "4   100001  citizens         98   1500.0             NaN              NaN   \n",
       "\n",
       "   career_win_rate  games_played  \n",
       "0              NaN             0  \n",
       "1              NaN             0  \n",
       "2              NaN             0  \n",
       "3              NaN             0  \n",
       "4              NaN             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_elos(df, init=1500, k=24):\n",
    "    \"\"\"\n",
    "    Pre-game Elo features:\n",
    "    - pre_elo:   global player skill\n",
    "    - pre_elo_side: player skill when playing this side ('mafia' or 'citizens')\n",
    "    - pre_elo_role: player skill when playing this exact role ('don','black','sheriff','red')\n",
    "    \"\"\"\n",
    "    df = df.sort_values('id').copy()\n",
    "    elo_global = {}\n",
    "    elo_side   = {}  # key: (player_id, side)\n",
    "    elo_role   = {}  # key: (player_id, role)\n",
    "\n",
    "    outs = []\n",
    "\n",
    "    for gid, g in df.groupby('game_id', sort=False):\n",
    "        cur = g.copy()\n",
    "\n",
    "        # pre-game ratings (BEFORE updating with this game's result)\n",
    "        cur['pre_elo']       = [elo_global.get(pid, init) for pid in cur['player_id']]\n",
    "        cur['pre_elo_side']  = [elo_side.get((pid, team), init) for pid, team in zip(cur['player_id'], cur['team'])]\n",
    "        cur['pre_elo_role']  = [elo_role.get((pid, role), init) for pid, role in zip(cur['player_id'], cur['role'])]\n",
    "\n",
    "        # expected result based on global ELO means (stable & data-rich)\n",
    "        maf = cur['team'].eq('mafia')\n",
    "        mafia_mean = cur.loc[maf, 'pre_elo'].mean()\n",
    "        cit_mean   = cur.loc[~maf, 'pre_elo'].mean()\n",
    "        exp_mafia  = 1.0 / (1.0 + 10 ** ((cit_mean - mafia_mean)/400))\n",
    "\n",
    "        mafia_res = int(cur.loc[maf, 'team_win'].iloc[0])\n",
    "        cit_res   = 1 - mafia_res\n",
    "\n",
    "        # update ratings AFTER the game\n",
    "        for _, r in cur.iterrows():\n",
    "            pid, side, role = r['player_id'], r['team'], r['role']\n",
    "            exp = exp_mafia if side == 'mafia' else (1 - exp_mafia)\n",
    "            act = mafia_res   if side == 'mafia' else (1 - mafia_res)\n",
    "            delta = k * (act - exp)\n",
    "            elo_global[pid] = elo_global.get(pid, init) + delta\n",
    "            elo_side[(pid, side)] = elo_side.get((pid, side), init) + delta\n",
    "            elo_role[(pid, role)] = elo_role.get((pid, role), init) + delta\n",
    "\n",
    "        outs.append(cur[['game_id','player_id','pre_elo','pre_elo_side','pre_elo_role']])\n",
    "\n",
    "    elo_df = pd.concat(outs, ignore_index=True)\n",
    "    return df.merge(elo_df, on=['game_id','player_id'], how='left')\n",
    "\n",
    "def add_rolling_stats_side(df, windows=(5, 20)):\n",
    "    \"\"\"\n",
    "    Adds BOTH:\n",
    "    - Generic per-player rolling: roll{w}_win_rate, games_played, career_win_rate\n",
    "    - Side-specific rolling:      roll{w}_win_rate_mafia, roll{w}_win_rate_citizens\n",
    "    All computed leakage-safe (uses shift(1)).\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['player_id','id']).copy()\n",
    "    out = []\n",
    "    for pid, g in df.groupby('player_id', sort=False):\n",
    "        g = g.copy()\n",
    "        g['win_shift'] = g['team_win'].shift(1)\n",
    "\n",
    "        # Generic rolling win-rates (all games for this player)\n",
    "        for w in windows:\n",
    "            g[f'roll{w}_win_rate'] = g['win_shift'].rolling(w, min_periods=1).mean()\n",
    "\n",
    "        # Side-specific rolling win-rates\n",
    "        for side in ['mafia','citizens']:\n",
    "            mask = g['team'].eq(side)\n",
    "            for w in windows:\n",
    "                g.loc[mask, f'roll{w}_win_rate_{side}'] = g.loc[mask, 'win_shift'].rolling(w, min_periods=1).mean()\n",
    "\n",
    "        # Career stats (overall)\n",
    "        g['games_played']   = np.arange(len(g))               # 0,1,2,... (pre-game count for current row)\n",
    "        g['career_win_rate'] = g['win_shift'].expanding().mean()\n",
    "\n",
    "        g.drop(columns=['win_shift'], inplace=True)\n",
    "        out.append(g)\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "def add_break_features(df, gap_thresh):\n",
    "    \"\"\"\n",
    "    Adds:\n",
    "    - gap_id: id difference since last game for this player (NaN for first game)\n",
    "    - long_break_flag: 1 if gap_id >= gap_thresh else 0\n",
    "    - gap_id_clipped: replace NaN with 0, clip huge tails for stability\n",
    "    \"\"\"\n",
    "    d = df.sort_values(['player_id','id']).copy()\n",
    "    d['gap_id'] = d.groupby('player_id')['id'].diff()\n",
    "    d['gap_id_clipped'] = d['gap_id'].fillna(0).clip(lower=0)\n",
    "    d['long_break_flag'] = (d['gap_id_clipped'] >= gap_thresh).astype('int8')\n",
    "    return d.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "work_players = compute_elos(df)\n",
    "work_players = add_rolling_stats_side(work_players)\n",
    "work_players = add_break_features(work_players, GAP_THRESH)\n",
    "\n",
    "# This preview now works again:\n",
    "work_players[['game_id','team','player_id',\n",
    "              'pre_elo',\n",
    "              'roll5_win_rate','roll20_win_rate','career_win_rate','games_played']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c60d6",
   "metadata": {},
   "source": [
    "### Synergy features (co-play history)\n",
    "For each game and team, compute how many times each pair of teammates had previously played together on the **same side**. Aggregate within the team (mean, max). Uses chronological order by `id`, no leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357fc3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team</th>\n",
       "      <th>synergy_mean_team</th>\n",
       "      <th>synergy_max_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id      team  synergy_mean_team  synergy_max_team\n",
       "0   100001  citizens                0.0               0.0\n",
       "1   100001  citizens                0.0               0.0\n",
       "2   100001     mafia                0.0               0.0\n",
       "3   100001     mafia                0.0               0.0\n",
       "4   100001  citizens                0.0               0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def add_synergy_features(df):\n",
    "    \"\"\"\n",
    "    For each game_id and team:\n",
    "      - Compute prior same-team co-plays for all unordered pairs within that team (before this game).\n",
    "      - Store team-level aggregates: synergy_mean_team, synergy_max_team.\n",
    "    Implementation detail:\n",
    "      - Iterate games in chronological order (by max id in the game).\n",
    "      - Maintain a dictionary that counts how many times pair (a,b) have co-played on a given side.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # game chronological order (by last id within game)\n",
    "    game_order = (df.groupby('game_id')['id'].max()\n",
    "                    .sort_values().index.tolist())\n",
    "\n",
    "    # dict key: (min(pid), max(pid), team) -> count of prior co-plays on that team\n",
    "    pair_counts = {}\n",
    "\n",
    "    # output rows: (game_id, team, synergy_mean, synergy_max)\n",
    "    out_rows = []\n",
    "\n",
    "    for gid in game_order:\n",
    "        g = df[df['game_id'] == gid]\n",
    "        for team in ['mafia', 'citizens']:\n",
    "            team_players = g.loc[g['team'] == team, 'player_id'].tolist()\n",
    "            pair_vals = []\n",
    "            for a, b in combinations(sorted(team_players), 2):\n",
    "                key = (a, b, team)\n",
    "                pair_vals.append(pair_counts.get(key, 0))\n",
    "\n",
    "            if len(pair_vals) == 0:\n",
    "                s_mean, s_max = 0.0, 0.0\n",
    "            else:\n",
    "                s_mean = float(np.mean(pair_vals))\n",
    "                s_max  = float(np.max(pair_vals))\n",
    "\n",
    "            out_rows.append((gid, team, s_mean, s_max))\n",
    "\n",
    "        # AFTER recording features, update counts with this game\n",
    "        for team in ['mafia', 'citizens']:\n",
    "            team_players = g.loc[g['team'] == team, 'player_id'].tolist()\n",
    "            for a, b in combinations(sorted(team_players), 2):\n",
    "                key = (a, b, team)\n",
    "                pair_counts[key] = pair_counts.get(key, 0) + 1\n",
    "\n",
    "    team_synergy = pd.DataFrame(out_rows, columns=['game_id','team','synergy_mean_team','synergy_max_team'])\n",
    "    # attach to every player-row (team-wise constant)\n",
    "    return df.merge(team_synergy, on=['game_id','team'], how='left')\n",
    "\n",
    "# AFTER: call it\n",
    "work_players = add_synergy_features(work_players)\n",
    "work_players[['game_id','team','synergy_mean_team','synergy_max_team']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c52010",
   "metadata": {},
   "source": [
    "### Streak features (momentum)\n",
    "Compute per-player **pre-game** win_streak and loss_streak using only past results. Aggregate to team (mean, max).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca2f1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>win_streak</th>\n",
       "      <th>loss_streak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id  player_id  win_streak  loss_streak\n",
       "0   100001          2           0            0\n",
       "1   100001         26           0            0\n",
       "2   100001         50           0            0\n",
       "3   100001         74           0            0\n",
       "4   100001         98           0            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_streak_features(df):\n",
    "    \"\"\"\n",
    "    Adds per-player pre-game streaks:\n",
    "      - win_streak: consecutive wins ending just before this game\n",
    "      - loss_streak: consecutive losses ending just before this game\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['player_id','id']).copy()\n",
    "    win_streaks = []\n",
    "    loss_streaks = []\n",
    "\n",
    "    for pid, g in df.groupby('player_id', sort=False):\n",
    "        prev = g['team_win'].shift(1).values  # past outcomes only\n",
    "        w_stk = np.zeros(len(g), dtype=np.int16)\n",
    "        l_stk = np.zeros(len(g), dtype=np.int16)\n",
    "        cur_w, cur_l = 0, 0\n",
    "        for i, v in enumerate(prev):\n",
    "            if np.isnan(v):\n",
    "                cur_w, cur_l = 0, 0\n",
    "            else:\n",
    "                if v == 1:  # previous result was win\n",
    "                    cur_w += 1\n",
    "                    cur_l = 0\n",
    "                else:       # previous result was loss\n",
    "                    cur_l += 1\n",
    "                    cur_w = 0\n",
    "            w_stk[i] = cur_w\n",
    "            l_stk[i] = cur_l\n",
    "        win_streaks.append(pd.Series(w_stk, index=g.index))\n",
    "        loss_streaks.append(pd.Series(l_stk, index=g.index))\n",
    "\n",
    "    df['win_streak']  = pd.concat(win_streaks).sort_index()\n",
    "    df['loss_streak'] = pd.concat(loss_streaks).sort_index()\n",
    "    return df.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "# AFTER: call it\n",
    "work_players = add_streak_features(work_players)\n",
    "work_players[['game_id','player_id','win_streak','loss_streak']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f767901",
   "metadata": {},
   "source": [
    "## 3) Aggregate to team level (two rows per game) + matchup deltas\n",
    "- Aggregate per-team: mean/std/min/max/q25/q75 of `pre_elo`; mean of rolling stats.\n",
    "- Create deltas: (mafia - citizens) for each aggregate to encode matchup strength.\n",
    "- Add: `team_win_team` (label) and `game_max_id` (time proxy per game).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce371c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team</th>\n",
       "      <th>pre_elo_mean</th>\n",
       "      <th>pre_elo_std</th>\n",
       "      <th>pre_elo_min</th>\n",
       "      <th>pre_elo_max</th>\n",
       "      <th>pre_elo_q25</th>\n",
       "      <th>pre_elo_q75</th>\n",
       "      <th>pre_elo_side_mean</th>\n",
       "      <th>pre_elo_role_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>roll20_win_rate_mafia_mean__delta_maf_minus_cit</th>\n",
       "      <th>roll5_win_rate_citizens_mean__delta_maf_minus_cit</th>\n",
       "      <th>roll20_win_rate_citizens_mean__delta_maf_minus_cit</th>\n",
       "      <th>don_pre_elo_role__delta_maf_minus_cit</th>\n",
       "      <th>sheriff_pre_elo_role__delta_maf_minus_cit</th>\n",
       "      <th>don_place__delta_maf_minus_cit</th>\n",
       "      <th>sheriff_place__delta_maf_minus_cit</th>\n",
       "      <th>black_mean_pre_elo_role__delta_maf_minus_cit</th>\n",
       "      <th>red_mean_pre_elo_role__delta_maf_minus_cit</th>\n",
       "      <th>game_max_id__delta_maf_minus_cit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>citizens</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id      team  pre_elo_mean  pre_elo_std  pre_elo_min  pre_elo_max  \\\n",
       "0   100001  citizens        1500.0          0.0       1500.0       1500.0   \n",
       "1   100001     mafia        1500.0          0.0       1500.0       1500.0   \n",
       "2   100002  citizens        1500.0          0.0       1500.0       1500.0   \n",
       "\n",
       "   pre_elo_q25  pre_elo_q75  pre_elo_side_mean  pre_elo_role_mean  ...  \\\n",
       "0       1500.0       1500.0             1500.0             1500.0  ...   \n",
       "1       1500.0       1500.0             1500.0             1500.0  ...   \n",
       "2       1500.0       1500.0             1500.0             1500.0  ...   \n",
       "\n",
       "   roll20_win_rate_mafia_mean__delta_maf_minus_cit  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "\n",
       "   roll5_win_rate_citizens_mean__delta_maf_minus_cit  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "\n",
       "   roll20_win_rate_citizens_mean__delta_maf_minus_cit  \\\n",
       "0                                                NaN    \n",
       "1                                                NaN    \n",
       "2                                                NaN    \n",
       "\n",
       "   don_pre_elo_role__delta_maf_minus_cit  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                                    NaN   \n",
       "\n",
       "   sheriff_pre_elo_role__delta_maf_minus_cit  don_place__delta_maf_minus_cit  \\\n",
       "0                                        NaN                             NaN   \n",
       "1                                        NaN                             NaN   \n",
       "2                                        NaN                             NaN   \n",
       "\n",
       "   sheriff_place__delta_maf_minus_cit  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "2                                 NaN   \n",
       "\n",
       "   black_mean_pre_elo_role__delta_maf_minus_cit  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "\n",
       "   red_mean_pre_elo_role__delta_maf_minus_cit  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "\n",
       "   game_max_id__delta_maf_minus_cit  \n",
       "0                                 0  \n",
       "1                                 0  \n",
       "2                                 0  \n",
       "\n",
       "[3 rows x 75 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q25(x): return x.quantile(0.25)\n",
    "\n",
    "def q75(x): return x.quantile(0.75)\n",
    "\n",
    "def build_team_agg(work_players):\n",
    "    # 1) Base numeric aggregates (+ seat, breaks, streaks, side/role elos)\n",
    "    agg_funcs = {\n",
    "        'pre_elo': ['mean','std','min','max', q25, q75],\n",
    "        'pre_elo_side': ['mean'],\n",
    "        'pre_elo_role': ['mean'],\n",
    "        'gap_id_clipped': ['mean','max'],\n",
    "        'long_break_flag': ['sum'],\n",
    "        'place': ['mean','std','min','max'],\n",
    "        'win_streak': ['mean','max'],\n",
    "        'loss_streak': ['mean','max'],\n",
    "        'synergy_mean_team': ['mean'],  # team-wise constant per game, but keep API consistent\n",
    "        'synergy_max_team':  ['mean'],\n",
    "        'games_played': ['mean','std','min','max'],  # ensure std included\n",
    "    }\n",
    "    for side in ['mafia','citizens']:\n",
    "        agg_funcs[f'roll5_win_rate_{side}']  = ['mean']\n",
    "        agg_funcs[f'roll20_win_rate_{side}'] = ['mean']\n",
    "\n",
    "    base = work_players.groupby(['game_id','team']).agg(agg_funcs)\n",
    "    base.columns = ['_'.join(filter(None, map(str, c))).replace('<function ','').replace('>','') for c in base.columns]\n",
    "    base = base.reset_index()\n",
    "\n",
    "    # 2) Role-specific Elo & seats\n",
    "    def single_role_stat(role, value_col):\n",
    "        s = (work_players[work_players['role'] == role]\n",
    "             .groupby(['game_id','team'])[value_col]\n",
    "             .mean()\n",
    "             .rename(f'{role}_{value_col}'))\n",
    "        \n",
    "        return s\n",
    "\n",
    "    don_elo     = single_role_stat('don', 'pre_elo_role')\n",
    "    sheriff_elo = single_role_stat('sheriff', 'pre_elo_role')\n",
    "    don_place   = single_role_stat('don', 'place')\n",
    "    sheriff_place = single_role_stat('sheriff', 'place')\n",
    "\n",
    "    def mean_role_stat(role, value_col):\n",
    "        s = (work_players[work_players['role'] == role]\n",
    "             .groupby(['game_id','team'])[value_col]\n",
    "             .mean()\n",
    "             .rename(f'{role}_mean_{value_col}'))\n",
    "        \n",
    "        return s\n",
    "\n",
    "    black_elo_mean = mean_role_stat('black', 'pre_elo_role')\n",
    "    red_elo_mean   = mean_role_stat('red', 'pre_elo_role')\n",
    "\n",
    "    role_feats = pd.concat([don_elo, sheriff_elo, don_place, sheriff_place,\n",
    "                            black_elo_mean, red_elo_mean], axis=1).reset_index()\n",
    "\n",
    "    team_agg = base.merge(role_feats, on=['game_id','team'], how='left')\n",
    "\n",
    "    # 3) Label & time proxy\n",
    "    labels  = work_players.groupby(['game_id','team'])['team_win'].max().rename('team_win_team')\n",
    "    gmaxid  = work_players.groupby('game_id')['id'].max().rename('game_max_id')\n",
    "    team_agg = team_agg.merge(labels, on=['game_id','team']).merge(gmaxid, on='game_id')\n",
    "\n",
    "    # 4) SAFE deltas\n",
    "    wide = team_agg.pivot(index='game_id', columns='team')\n",
    "    wide.columns = [f\"{a}__{b}\" for a,b in wide.columns]\n",
    "    wide = wide.reset_index()\n",
    "\n",
    "    def side_cols(side): return [c for c in wide.columns if c.endswith(f\"__{side}\") and c != 'game_id']\n",
    "    maf_cols = side_cols('mafia')\n",
    "\n",
    "    delta = pd.DataFrame({'game_id': wide['game_id']})\n",
    "\n",
    "    for mcol in maf_cols:\n",
    "        if 'team_win_team' in mcol:\n",
    "            continue  # never delta the target\n",
    "        base_name = mcol[:-len(\"__mafia\")]\n",
    "        ccol = base_name + \"__citizens\"\n",
    "        if ccol in wide.columns:\n",
    "            delta[base_name + \"__delta_maf_minus_cit\"] = wide[mcol] - wide[ccol]\n",
    "\n",
    "    team_tall = team_agg.merge(delta, on='game_id', how='left')\n",
    "    \n",
    "    return team_tall\n",
    "\n",
    "# build new team dataset\n",
    "team_tall = build_team_agg(work_players)\n",
    "\n",
    "# Save aggregated dataset\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "team_tall.to_csv(OUT_DIR/\"mafia_team_agg.csv\", index=False)\n",
    "team_tall.to_parquet(OUT_DIR/\"mafia_team_agg.parquet\", index=False)\n",
    "team_tall.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c123447",
   "metadata": {},
   "source": [
    "## 4) Features, CV strategy, and baselines\n",
    "- `X`: team aggregates + delta features\n",
    "- `y`: `team_win_team`\n",
    "- `groups`: `game_id`\n",
    "- Chronological split by `game_max_id` (70/15/15) for calibration & final holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d1c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_only = [c for c in team_tall.columns if c.startswith((\n",
    "    'pre_elo_', 'gap_id_clipped_', 'long_break_flag_',\n",
    "    'place_', 'win_streak_', 'loss_streak_',\n",
    "    'synergy_mean_team_', 'synergy_max_team_',\n",
    "    'games_played_', 'don_pre_elo_role', 'sheriff_pre_elo_role',\n",
    "    'don_place', 'sheriff_place', 'black_mean_pre_elo_role', 'red_mean_pre_elo_role',\n",
    "    'roll5_win_rate_mafia_', 'roll20_win_rate_mafia_', 'roll5_win_rate_citizens_', 'roll20_win_rate_citizens_'\n",
    "))]\n",
    "\n",
    "delta_feats = [c for c in team_tall.columns if c.endswith('__delta_maf_minus_cit')]\n",
    "\n",
    "forbidden_tokens = {'team_win','team_win_team'}\n",
    "USED_FEATS = [c for c in sorted(set(team_only + delta_feats))\n",
    "              if not any(tok in c for tok in forbidden_tokens)]\n",
    "\n",
    "X = team_tall[USED_FEATS].fillna(0)\n",
    "y = team_tall['team_win_team'].astype(int).values\n",
    "groups = team_tall['game_id'].values\n",
    "time_key = team_tall['game_max_id'].values\n",
    "\n",
    "q70, q85 = np.quantile(time_key, [0.70, 0.85])\n",
    "train_mask = time_key <= q85\n",
    "cal_mask   = (time_key > q70) & (time_key <= q85)\n",
    "test_mask  = time_key > q85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77acc2f9",
   "metadata": {},
   "source": [
    "### Removing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0d9e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Near-constant features: ['black_mean_pre_elo_role__delta_maf_minus_cit', 'don_place__delta_maf_minus_cit', 'don_pre_elo_role__delta_maf_minus_cit', 'game_max_id__delta_maf_minus_cit', 'red_mean_pre_elo_role__delta_maf_minus_cit', 'roll20_win_rate_citizens_mean__delta_maf_minus_cit', 'roll20_win_rate_mafia_mean__delta_maf_minus_cit', 'roll5_win_rate_citizens_mean__delta_maf_minus_cit', 'roll5_win_rate_mafia_mean__delta_maf_minus_cit', 'sheriff_place__delta_maf_minus_cit', 'sheriff_pre_elo_role__delta_maf_minus_cit']\n",
      "Highly collinear to drop: ['don_pre_elo_role', 'red_mean_pre_elo_role', 'roll5_win_rate_citizens_mean', 'roll5_win_rate_mafia_mean', 'sheriff_pre_elo_role']\n"
     ]
    }
   ],
   "source": [
    "low_var = X.columns[X.std() < 1e-6]\n",
    "print(\"Near-constant features:\", list(low_var))\n",
    "X.drop(columns=low_var, inplace=True)\n",
    "USED_FEATS = [c for c in USED_FEATS if c not in set(low_var)]\n",
    "\n",
    "corr = X[train_mask].corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "to_drop = [col for col in upper.columns if (upper[col] > 0.98).any()]\n",
    "print(\"Highly collinear to drop:\", to_drop[:20])\n",
    "X.drop(columns=to_drop, inplace=True)\n",
    "USED_FEATS = [c for c in USED_FEATS if c not in set(to_drop)]\n",
    "\n",
    "# # quick one-pass using final model (or average across folds if you saved them)\n",
    "# imp = pd.DataFrame({'feature': X.columns,\n",
    "#                     'gain': final.booster_.feature_importance(importance_type='gain')})\n",
    "# zero_imp = imp.loc[imp['gain'] == 0, 'feature'].tolist()\n",
    "# print(\"Zero-importance:\", zero_imp[:20])\n",
    "# X.drop(columns=zero_imp, inplace=True)\n",
    "# USED_FEATS = [c for c in USED_FEATS if c not in set(zero_imp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b8985d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 55\n",
      "Rows: 160564 | Train: 136480 Cal: 24084 Test: 24084\n"
     ]
    }
   ],
   "source": [
    "print(\"Features:\", len(USED_FEATS))\n",
    "print(\"Rows:\", len(team_tall), \"| Train:\", train_mask.sum(), \"Cal:\", cal_mask.sum(), \"Test:\", test_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7a2428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline-0 (holdout) LogLoss: 0.6931471805599454\n",
      "Baseline-0 (holdout) Brier  : 0.25\n",
      "Baseline-1 (LogReg) | LogLoss 0.6841±0.0010 | AUC 0.5746±0.0039 | Brier 0.2455±0.0005\n"
     ]
    }
   ],
   "source": [
    "# Baseline-0 constant 0.5 on holdout\n",
    "p_const = np.repeat(0.5, len(y))\n",
    "print(\"Baseline-0 (holdout) LogLoss:\", log_loss(y[test_mask], p_const[test_mask]))\n",
    "print(\"Baseline-0 (holdout) Brier  :\", brier_score_loss(y[test_mask], p_const[test_mask]))\n",
    "# ROC-AUC is undefined for a constant predictor; skip.\n",
    "\n",
    "# Baseline-1 Logistic Regression with GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "logreg = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=True)),  # center & scale (X is dense)\n",
    "    ('lr', LogisticRegression(\n",
    "        max_iter=5000,          # more steps\n",
    "        solver='lbfgs',         # good default for L2\n",
    "        penalty='l2',\n",
    "        n_jobs=-1,\n",
    "        random_state=SEED\n",
    "    ))\n",
    "])\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "lls, aucs, brs = [], [], []\n",
    "for tr, va in gkf.split(X, y, groups=groups):\n",
    "    logreg.fit(X.iloc[tr], y[tr])\n",
    "    p = logreg.predict_proba(X.iloc[va])[:,1]\n",
    "    lls.append(log_loss(y[va], p))\n",
    "    aucs.append(roc_auc_score(y[va], p))\n",
    "    brs.append(brier_score_loss(y[va], p))\n",
    "print(f\"Baseline-1 (LogReg) | LogLoss {np.mean(lls):.4f}±{np.std(lls):.4f} | \"\n",
    "      f\"AUC {np.mean(aucs):.4f}±{np.std(aucs):.4f} | Brier {np.mean(brs):.4f}±{np.std(brs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e92f984",
   "metadata": {},
   "source": [
    "## 5) LightGBM (main model) + CV + calibration + holdout\n",
    "### Model tuning (LightGBM)\n",
    "Slightly higher capacity + early stopping + class_weight='balanced'. Calibrate with sigmoid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e2da86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 64225, number of negative: 64225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8362\n",
      "[LightGBM] [Info] Number of data points in the train set: 128450, number of used features: 55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's binary_logloss: 0.68381\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Fold 1: LogLoss=0.6838 AUC=0.5770 Brier=0.2453\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 64225, number of negative: 64225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8364\n",
      "[LightGBM] [Info] Number of data points in the train set: 128450, number of used features: 55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's binary_logloss: 0.683333\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Fold 2: LogLoss=0.6833 AUC=0.5796 Brier=0.2451\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 64226, number of negative: 64226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8356\n",
      "[LightGBM] [Info] Number of data points in the train set: 128452, number of used features: 55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's binary_logloss: 0.684927\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Fold 3: LogLoss=0.6849 AUC=0.5720 Brier=0.2459\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 64226, number of negative: 64226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8362\n",
      "[LightGBM] [Info] Number of data points in the train set: 128452, number of used features: 55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's binary_logloss: 0.684935\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Fold 4: LogLoss=0.6849 AUC=0.5725 Brier=0.2459\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 64226, number of negative: 64226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8363\n",
      "[LightGBM] [Info] Number of data points in the train set: 128452, number of used features: 55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[365]\tvalid_0's binary_logloss: 0.681971\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Fold 5: LogLoss=0.6820 AUC=0.5846 Brier=0.2444\n",
      "\n",
      "CV | LogLoss 0.6838±0.0011 | AUC 0.5771±0.0047 | Brier 0.2453±0.0005\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8380\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's binary_logloss: 0.684068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\George\\anaconda3\\envs\\mafia_analysis\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "\n",
      "Holdout (last 15%)\n",
      "LogLoss: 0.6810904739046589\n",
      "ROC-AUC: 0.5912541792703008\n",
      "Brier  : 0.243958086341504\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import numpy as np\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=127,\n",
    "    min_data_in_leaf=40,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.5,\n",
    "    reg_alpha=0.3,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "lls, aucs, brs = [], [], []\n",
    "for k,(tr,va) in enumerate(gkf.split(X,y,groups=groups),1):\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(\n",
    "    X.iloc[tr], y[tr],\n",
    "    eval_set=[(X.iloc[va], y[va])],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=100),  # same meaning as early_stopping_rounds\n",
    "        log_evaluation(0)                     # silences per-iteration logs; use log_evaluation(50) to see progress\n",
    "    ]\n",
    ")\n",
    "    p = model.predict_proba(X.iloc[va])[:,1]\n",
    "    lls.append(log_loss(y[va], p)); aucs.append(roc_auc_score(y[va], p)); brs.append(brier_score_loss(y[va], p))\n",
    "    print(f\"Fold {k}: LogLoss={lls[-1]:.4f} AUC={aucs[-1]:.4f} Brier={brs[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\nCV | LogLoss {np.mean(lls):.4f}±{np.std(lls):.4f} | \"\n",
    "      f\"AUC {np.mean(aucs):.4f}±{np.std(aucs):.4f} | Brier {np.mean(brs):.4f}±{np.std(brs):.4f}\")\n",
    "\n",
    "q70, q85 = np.quantile(time_key, [0.70, 0.85])\n",
    "train_mask = time_key <= q85\n",
    "cal_mask   = (time_key > q70) & (time_key <= q85)\n",
    "test_mask  = time_key > q85\n",
    "\n",
    "# make a tiny val split from the train window (e.g., last 10% by time among train_mask)\n",
    "tr_time = time_key[train_mask]\n",
    "tr_q90 = np.quantile(tr_time, 0.90)\n",
    "inner_tr = train_mask & (time_key <= tr_q90)\n",
    "inner_va = train_mask & (time_key >  tr_q90)\n",
    "\n",
    "final = LGBMClassifier(**params)\n",
    "final.fit(\n",
    "    X[inner_tr], y[inner_tr],\n",
    "    eval_set=[(X[inner_va], y[inner_va])],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[early_stopping(stopping_rounds=100), log_evaluation(0)]\n",
    ")\n",
    "\n",
    "\n",
    "calibrated = CalibratedClassifierCV(final, cv='prefit', method='sigmoid').fit(X[cal_mask], y[cal_mask])\n",
    "\n",
    "p_test = calibrated.predict_proba(X[test_mask])[:,1]\n",
    "print(\"\\nHoldout (last 15%)\")\n",
    "print(\"LogLoss:\", log_loss(y[test_mask], p_test))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y[test_mask], p_test))\n",
    "print(\"Brier  :\", brier_score_loss(y[test_mask], p_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c448f0c",
   "metadata": {},
   "source": [
    "### Feature cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6e0ecce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>black_mean_pre_elo_role</td>\n",
       "      <td>83972.693232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>don_place</td>\n",
       "      <td>15973.395452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pre_elo_side_mean__delta_maf_minus_cit</td>\n",
       "      <td>13711.242615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>place_std__delta_maf_minus_cit</td>\n",
       "      <td>10598.319596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pre_elo_q25__delta_maf_minus_cit</td>\n",
       "      <td>10245.660873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gap_id_clipped_mean__delta_maf_minus_cit</td>\n",
       "      <td>9368.866647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>pre_elo_role_mean__delta_maf_minus_cit</td>\n",
       "      <td>8837.018718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pre_elo_side_mean</td>\n",
       "      <td>8660.291512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pre_elo_role_mean</td>\n",
       "      <td>8497.468383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>pre_elo_q75</td>\n",
       "      <td>8256.890153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pre_elo_q75__delta_maf_minus_cit</td>\n",
       "      <td>8180.615067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pre_elo_min__delta_maf_minus_cit</td>\n",
       "      <td>8142.575258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>pre_elo_std__delta_maf_minus_cit</td>\n",
       "      <td>8050.208198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gap_id_clipped_mean</td>\n",
       "      <td>7708.883282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pre_elo_mean__delta_maf_minus_cit</td>\n",
       "      <td>7643.900032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature          gain\n",
       "0                    black_mean_pre_elo_role  83972.693232\n",
       "1                                  don_place  15973.395452\n",
       "41    pre_elo_side_mean__delta_maf_minus_cit  13711.242615\n",
       "27            place_std__delta_maf_minus_cit  10598.319596\n",
       "35          pre_elo_q25__delta_maf_minus_cit  10245.660873\n",
       "13  gap_id_clipped_mean__delta_maf_minus_cit   9368.866647\n",
       "39    pre_elo_role_mean__delta_maf_minus_cit   8837.018718\n",
       "40                         pre_elo_side_mean   8660.291512\n",
       "38                         pre_elo_role_mean   8497.468383\n",
       "36                               pre_elo_q75   8256.890153\n",
       "37          pre_elo_q75__delta_maf_minus_cit   8180.615067\n",
       "33          pre_elo_min__delta_maf_minus_cit   8142.575258\n",
       "43          pre_elo_std__delta_maf_minus_cit   8050.208198\n",
       "12                       gap_id_clipped_mean   7708.883282\n",
       "31         pre_elo_mean__delta_maf_minus_cit   7643.900032"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fi = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'gain': final.booster_.feature_importance(importance_type='gain')\n",
    "}).sort_values('gain', ascending=False)\n",
    "fi.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb7b3c",
   "metadata": {},
   "source": [
    "### Sanity-Check 0 — Context\n",
    "We assume you already have these variables from the notebook:\n",
    "- `team_tall`  : the per-team dataset (2 rows per game)\n",
    "- `USED_FEATS` : the list of feature column names used to train\n",
    "- `X, y`       : features (DataFrame) and labels (numpy array)\n",
    "- `groups`     : `game_id` for GroupKFold\n",
    "- `time_key`   : `game_max_id` (time proxy per game)\n",
    "- masks: `train_mask`, `cal_mask`, `test_mask`\n",
    "- models: `final` (LightGBM before calibration), `calibrated` (after isotonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43424ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "RAW (no calibration) — holdout\n",
      "LogLoss: 0.6806256995681352\n",
      "AUC    : 0.5912541792703008\n",
      "Brier  : 0.2437700147688812\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "\n",
      "CALIBRATED — holdout\n",
      "LogLoss: 0.6810904739046589\n",
      "AUC    : 0.5912541792703008\n",
      "Brier  : 0.243958086341504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss\n",
    "\n",
    "# Raw (uncalibrated) predictions on holdout\n",
    "p_test_raw = final.predict_proba(X[test_mask])[:, 1]\n",
    "print(\"RAW (no calibration) — holdout\")\n",
    "print(\"LogLoss:\", log_loss(y[test_mask], p_test_raw))\n",
    "print(\"AUC    :\", roc_auc_score(y[test_mask], p_test_raw))\n",
    "print(\"Brier  :\", brier_score_loss(y[test_mask], p_test_raw))\n",
    "\n",
    "# Calibrated (your current numbers)\n",
    "p_test_cal = calibrated.predict_proba(X[test_mask])[:, 1]\n",
    "print(\"\\nCALIBRATED — holdout\")\n",
    "print(\"LogLoss:\", log_loss(y[test_mask], p_test_cal))\n",
    "print(\"AUC    :\", roc_auc_score(y[test_mask], p_test_cal))\n",
    "print(\"Brier  :\", brier_score_loss(y[test_mask], p_test_cal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aa1c8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label-shuffled holdout:\n",
      "LogLoss: 0.7147548988978578\n",
      "AUC    : 0.5003733989940153\n",
      "Brier  : 0.26041983603755\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "y_shuffled = y.copy()\n",
    "y_shuffled[test_mask] = rng.permutation(y_shuffled[test_mask])\n",
    "\n",
    "print(\"Label-shuffled holdout:\")\n",
    "print(\"LogLoss:\", log_loss(y_shuffled[test_mask], p_test_cal))\n",
    "print(\"AUC    :\", roc_auc_score(y_shuffled[test_mask], p_test_cal))\n",
    "print(\"Brier  :\", brier_score_loss(y_shuffled[test_mask], p_test_cal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f72ffb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Feature-shuffled holdout:\n",
      "LogLoss: 0.7133639023716307\n",
      "AUC    : 0.5044940318639509\n",
      "Brier  : 0.25976301299755994\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the order of X within the holdout\n",
    "X_test = X[test_mask].copy()\n",
    "X_test_shuffled = X_test.sample(frac=1.0, random_state=123)\n",
    "\n",
    "# Predict on shuffled features (same trained model)\n",
    "p_test_shufX = calibrated.predict_proba(X_test_shuffled)[:, 1]\n",
    "\n",
    "print(\"Feature-shuffled holdout:\")\n",
    "print(\"LogLoss:\", log_loss(y[test_mask], p_test_shufX))\n",
    "print(\"AUC    :\", roc_auc_score(y[test_mask], p_test_shufX))\n",
    "print(\"Brier  :\", brier_score_loss(y[test_mask], p_test_shufX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e3ef431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forbidden features found: []\n"
     ]
    }
   ],
   "source": [
    "suspects = {'team_win','team_win_team',\n",
    "            'game_points','total_points',\n",
    "            'game_bonus','game_autobonus','best_move_bonus',\n",
    "            'killed_first','best_move'}\n",
    "bad = [c for c in USED_FEATS if any(s in c for s in suspects)]\n",
    "print(\"Forbidden features found:\", bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c284a",
   "metadata": {},
   "source": [
    "## 6) Convert to per-game winner & accuracy\n",
    "Pick the side with larger probability within each game on the holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a90fe3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-game accuracy (holdout): 0.5797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\George\\AppData\\Local\\Temp\\ipykernel_18400\\2849635908.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pred_side = hold.groupby('game_id').apply(lambda g: g.loc[g['proba'].idxmax(),'team'])\n"
     ]
    }
   ],
   "source": [
    "hold = team_tall.loc[test_mask, ['game_id','team','team_win_team']].copy()\n",
    "hold['proba'] = p_test\n",
    "\n",
    "# True side per game\n",
    "true_side = hold[hold['team_win_team']==1].groupby('game_id')['team'].first()\n",
    "\n",
    "# Predicted side by higher prob\n",
    "pred_side = hold.groupby('game_id').apply(lambda g: g.loc[g['proba'].idxmax(),'team'])\n",
    "acc = (pred_side == true_side.reindex(pred_side.index)).mean()\n",
    "print(\"Per-game accuracy (holdout):\", round(acc, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c98c4",
   "metadata": {},
   "source": [
    "## 7) Save model & inference helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f31981a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: artifacts_game\n",
      "Inference functions ready.\n"
     ]
    }
   ],
   "source": [
    "import joblib, json\n",
    "\n",
    "joblib.dump(calibrated, ARTS/\"lgbm_calibrated_pergame.joblib\")\n",
    "json.dump(USED_FEATS, open(ARTS/\"pergame_features.json\",\"w\"))\n",
    "print(\"Saved to:\", ARTS)\n",
    "\n",
    "def build_team_features_from_players(df_players: pd.DataFrame) -> pd.DataFrame:\n",
    "    w = compute_elo(df_players)\n",
    "    w = add_rolling_stats(w)\n",
    "\n",
    "    aggs = {\n",
    "        'pre_elo': ['mean','std','min','max', q25, q75],\n",
    "        'roll5_win_rate': ['mean'],\n",
    "        'roll20_win_rate': ['mean'],\n",
    "        'career_win_rate': ['mean'],\n",
    "        'games_played': ['mean','min','max', 'std']\n",
    "    }\n",
    "    if 'roll5_pts_mean' in w.columns:\n",
    "        aggs['roll5_pts_mean'] = ['mean']\n",
    "    if 'roll20_pts_mean' in w.columns:\n",
    "        aggs['roll20_pts_mean'] = ['mean']\n",
    "\n",
    "    ta = w.groupby(['game_id','team']).agg(aggs)\n",
    "    ta.columns = ['_'.join(filter(None, map(str, c))).replace('<function ','').replace('>','') for c in ta.columns]\n",
    "    ta = ta.reset_index()\n",
    "    if 'id' in w.columns:\n",
    "        gmaxid = w.groupby('game_id')['id'].max().rename('game_max_id')\n",
    "        ta = ta.merge(gmaxid, on='game_id', how='left')\n",
    "\n",
    "    wide = ta.pivot(index='game_id', columns='team')\n",
    "    wide.columns = [f\"{a}__{b}\" for a,b in wide.columns]\n",
    "    wide = wide.reset_index()\n",
    "\n",
    "    def side_cols(side): return [c for c in wide.columns if c.endswith(f\"__{side}\") and c != 'game_id']\n",
    "    maf_cols = side_cols('mafia')\n",
    "\n",
    "    delta = pd.DataFrame({'game_id': wide['game_id']})\n",
    "    for mcol in maf_cols:\n",
    "        base = mcol[:-len(\"__mafia\")]\n",
    "        ccol = base + \"__citizens\"\n",
    "        if ccol in wide.columns:\n",
    "            delta[base + \"__delta_maf_minus_cit\"] = wide[mcol] - wide[ccol]\n",
    "\n",
    "    team_tall_new = ta.merge(delta, on='game_id', how='left')\n",
    "    return team_tall_new\n",
    "\n",
    "def predict_game_winner_from_players(df_players_new: pd.DataFrame):\n",
    "    tt = build_team_features_from_players(df_players_new)\n",
    "    X_new = tt[USED_FEATS].fillna(0)\n",
    "    proba = calibrated.predict_proba(X_new)[:,1]\n",
    "    out = tt[['game_id','team']].copy()\n",
    "    out['p_team_win'] = proba\n",
    "    winners = out.loc[out.groupby('game_id')['p_team_win'].idxmax()].rename(columns={'team':'pred_team'})\n",
    "    winners = winners[['game_id','pred_team','p_team_win']]\n",
    "    return out, winners\n",
    "\n",
    "print(\"Inference functions ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4a7bc",
   "metadata": {},
   "source": [
    "## 8) “Daily” monitoring (simulated)\n",
    "Score newest ~2% of games by `game_max_id` to catch recent drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d11514c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "DAILY LogLoss: 0.6759773134520557\n",
      "DAILY ROC-AUC: 0.6053565862139021\n",
      "DAILY Brier  : 0.2414604019967574\n"
     ]
    }
   ],
   "source": [
    "cut = np.quantile(time_key, 0.98)\n",
    "daily_mask = time_key > cut\n",
    "p_daily = calibrated.predict_proba(X[daily_mask])[:,1]\n",
    "print(\"DAILY LogLoss:\", log_loss(y[daily_mask], p_daily))\n",
    "print(\"DAILY ROC-AUC:\", roc_auc_score(y[daily_mask], p_daily))\n",
    "print(\"DAILY Brier  :\", brier_score_loss(y[daily_mask], p_daily))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56552fb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mafia_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
