{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e06612",
   "metadata": {},
   "source": [
    "# Mafia — Per-Game Outcome Modeling (Pre-Game Only)\n",
    "\n",
    "Goal: predict the **winning side** (mafia vs citizens) from the lineup and past form.\n",
    "- Label per team row: `team_win_team` (1/0)\n",
    "- Validation: GroupKFold by `game_id` + chronological holdout by `game_max_id`\n",
    "- Metrics: LogLoss (primary), ROC-AUC, Brier, per-game accuracy\n",
    "- Features: per-player Elo & rolling stats → aggregated to team → deltas (mafia - citizens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1978a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy lightgbm scikit-learn pyarrow fastparquet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "DATA_PLAYERS = Path(\"cleaned/mafia_clean.csv\")  # cleaned player-level dataset\n",
    "OUT_DIR = Path(\"./team_data\"); OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "ARTS = Path(\"./artifacts_game\"); ARTS.mkdir(exist_ok=True, parents=True)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c8c49",
   "metadata": {},
   "source": [
    "## 1) Load cleaned player-level data\n",
    "We expect: 10 rows per game, 3 mafia / 7 citizens, winners per game ∈ {3,7}, no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65fdb7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27188\\3333621096.py:1: DtypeWarning: Columns (16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(DATA_PLAYERS)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((802820, 21),\n",
       "         id  game_id  place  player_id original_nickname   role  killed_first  \\\n",
       " 0  1000001   100001     10          2             Teddy    red             0   \n",
       " 1  1000002   100001      7         26          Искатель    red             0   \n",
       " 2  1000003   100001      9         50             Лоску  black             0   \n",
       " \n",
       "    best_move  game_points  game_autobonus  ...  best_move_bonus  penalty  \\\n",
       " 0          0          0.0             0.0  ...              0.0      0.0   \n",
       " 1          0          0.0             0.0  ...              0.0      0.0   \n",
       " 2          0          2.0             0.0  ...              0.0      0.0   \n",
       " \n",
       "    fouls  penalty_disciplinary   Ci  created_at updated_at      team team_win  \\\n",
       " 0    0.0                   0.0  0.0         NaN        NaN  citizens        0   \n",
       " 1    0.0                   0.0  0.0         NaN        NaN  citizens        0   \n",
       " 2    0.0                   0.0  0.0         NaN        NaN     mafia        1   \n",
       " \n",
       "    total_points  \n",
       " 0           0.0  \n",
       " 1           0.0  \n",
       " 2           2.0  \n",
       " \n",
       " [3 rows x 21 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PLAYERS)\n",
    "df.shape, df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6bc5da",
   "metadata": {},
   "source": [
    "## 2) Pre-game player features: Elo + rolling stats (leakage-safe)\n",
    "- Sort by `id` (time proxy).\n",
    "- Elo updates only from past results.\n",
    "- Rolling win rate (5, 20), career win rate, games played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01b8803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    732003.000000\n",
      "mean        135.976756\n",
      "std        1368.720034\n",
      "min           1.000000\n",
      "50%          42.000000\n",
      "80%         127.000000\n",
      "90%         228.000000\n",
      "95%         381.000000\n",
      "99%        1174.000000\n",
      "max      245724.000000\n",
      "Name: id, dtype: float64\n",
      "Chosen GAP_THRESH (id units): 381.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect distribution of per-player id gaps\n",
    "tmp = (df.sort_values(['player_id','id'])\n",
    "         .groupby('player_id')['id']\n",
    "         .diff()\n",
    "         .dropna())\n",
    "print(tmp.describe(percentiles=[.5,.8,.9,.95,.99]))\n",
    "\n",
    "# Choose a threshold (start with the 95th percentile as a proxy)\n",
    "GAP_THRESH = tmp.quantile(0.95)\n",
    "print(\"Chosen GAP_THRESH (id units):\", GAP_THRESH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f4f621",
   "metadata": {},
   "source": [
    "## Temporal ELO decay\n",
    "Scale each ELO update by exp(-gap/τ) where gap is the player's id-gap since last game.\n",
    "- τ controls how fast old games “fade” (τ=400).\n",
    "- Uses per-player gap computed on the fly; still pre-game safe (we take `pre_elo*` before updating).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef833f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_elos(df, init=1500, k=24, tau=400.0):\n",
    "    \"\"\"\n",
    "    Pre-game ELO features with **temporal decay** on updates.\n",
    "    - pre_elo:       global player skill\n",
    "    - pre_elo_side:  skill by side ('mafia'/'citizens')\n",
    "    - pre_elo_role:  skill by role ('don'/'black'/'sheriff'/'red')\n",
    "    decay factor per player update: exp( - gap_id_player / tau )\n",
    "    \"\"\"\n",
    "    d = df.sort_values('id').copy()\n",
    "\n",
    "    elo_global = {}\n",
    "    elo_side   = {}  # (player_id, side)\n",
    "    elo_role   = {}  # (player_id, role)\n",
    "    last_seen  = {}  # player_id -> last id seen\n",
    "\n",
    "    outs = []\n",
    "\n",
    "    for gid, g in d.groupby('game_id', sort=False):\n",
    "        cur = g.copy()\n",
    "        cur['pre_elo']       = [elo_global.get(pid, init) for pid in cur['player_id']]\n",
    "        cur['pre_elo_side']  = [elo_side.get((pid, team), init) for pid, team in zip(cur['player_id'], cur['team'])]\n",
    "        cur['pre_elo_role']  = [elo_role.get((pid, role), init) for pid, role in zip(cur['player_id'], cur['role'])]\n",
    "\n",
    "        maf_mask = cur['team'].eq('mafia')\n",
    "        mafia_mean = cur.loc[maf_mask, 'pre_elo'].mean()\n",
    "        cit_mean   = cur.loc[~maf_mask, 'pre_elo'].mean()\n",
    "        exp_mafia  = 1.0 / (1.0 + 10 ** ((cit_mean - mafia_mean)/400))\n",
    "\n",
    "        mafia_res = int(cur.loc[maf_mask, 'team_win'].iloc[0])\n",
    "\n",
    "        # update AFTER the game with **decay**\n",
    "        for _, r in cur.iterrows():\n",
    "            pid, side, role, rid = int(r['player_id']), r['team'], r['role'], int(r['id'])\n",
    "            gap = rid - last_seen.get(pid, rid)  # 0 for first appearance\n",
    "            decay = float(np.exp(-max(gap, 0) / float(tau)))\n",
    "\n",
    "            exp = exp_mafia if side == 'mafia' else (1 - exp_mafia)\n",
    "            act = mafia_res   if side == 'mafia' else (1 - mafia_res)\n",
    "            delta = k * decay * (act - exp)\n",
    "\n",
    "            elo_global[pid] = elo_global.get(pid, init) + delta\n",
    "            elo_side[(pid, side)] = elo_side.get((pid, side), init) + delta\n",
    "            elo_role[(pid, role)] = elo_role.get((pid, role), init) + delta\n",
    "            last_seen[pid] = rid\n",
    "\n",
    "        outs.append(cur[['game_id','player_id','pre_elo','pre_elo_side','pre_elo_role']])\n",
    "\n",
    "    elo_df = pd.concat(outs, ignore_index=True)\n",
    "    return d.merge(elo_df, on=['game_id','player_id'], how='left')\n",
    "\n",
    "def add_rolling_stats_side(df, windows=(5, 20)):\n",
    "    \"\"\"\n",
    "    Adds BOTH:\n",
    "    - Generic per-player rolling: roll{w}_win_rate, games_played, career_win_rate\n",
    "    - Side-specific rolling:      roll{w}_win_rate_mafia, roll{w}_win_rate_citizens\n",
    "    All computed leakage-safe (uses shift(1)).\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['player_id','id']).copy()\n",
    "    out = []\n",
    "    for pid, g in df.groupby('player_id', sort=False):\n",
    "        g = g.copy()\n",
    "        g['win_shift'] = g['team_win'].shift(1)\n",
    "\n",
    "        # Generic rolling win-rates (all games for this player)\n",
    "        for w in windows:\n",
    "            g[f'roll{w}_win_rate'] = g['win_shift'].rolling(w, min_periods=1).mean()\n",
    "\n",
    "        # Side-specific rolling win-rates\n",
    "        for side in ['mafia','citizens']:\n",
    "            mask = g['team'].eq(side)\n",
    "            for w in windows:\n",
    "                g.loc[mask, f'roll{w}_win_rate_{side}'] = g.loc[mask, 'win_shift'].rolling(w, min_periods=1).mean()\n",
    "\n",
    "        # Career stats (overall)\n",
    "        g['games_played']   = np.arange(len(g))               # 0,1,2,... (pre-game count for current row)\n",
    "        g['career_win_rate'] = g['win_shift'].expanding().mean()\n",
    "\n",
    "        g.drop(columns=['win_shift'], inplace=True)\n",
    "        out.append(g)\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "def add_break_features(df, gap_thresh):\n",
    "    \"\"\"\n",
    "    Adds:\n",
    "    - gap_id: id difference since last game for this player (NaN for first game)\n",
    "    - long_break_flag: 1 if gap_id >= gap_thresh else 0\n",
    "    - gap_id_clipped: replace NaN with 0, clip huge tails for stability\n",
    "    \"\"\"\n",
    "    d = df.sort_values(['player_id','id']).copy()\n",
    "    d['gap_id'] = d.groupby('player_id')['id'].diff()\n",
    "    d['gap_id_clipped'] = d['gap_id'].fillna(0).clip(lower=0)\n",
    "    d['long_break_flag'] = (d['gap_id_clipped'] >= gap_thresh).astype('int8')\n",
    "    return d.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "bins  = [0, 200_000, 400_000, 600_000, 800_000, 1_000_000_000]\n",
    "labels= [1, 2, 3, 4, 5]\n",
    "df = df.copy()\n",
    "df['meta_period'] = pd.cut(df['id'], bins=bins, labels=labels, include_lowest=True).astype('int8')\n",
    "\n",
    "work_players = compute_elos(df, init=1500, k=24, tau=400.0)\n",
    "work_players = work_players.merge(df[['id','meta_period']], on='id', how='left')\n",
    "work_players = add_rolling_stats_side(work_players)\n",
    "work_players = add_break_features(work_players, GAP_THRESH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b04c10",
   "metadata": {},
   "source": [
    "## Role-specific history (player-level)\n",
    "We add pre-game features that track a player's performance **on the exact role**:\n",
    "- `win_rate_role_<role>_lastW` for W in {5, 20, 50}\n",
    "- `games_in_role`: count of prior games on this role\n",
    "All computed with chronological order by `id` and `.shift(1)` to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed45abb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team</th>\n",
       "      <th>player_id</th>\n",
       "      <th>role</th>\n",
       "      <th>games_in_role</th>\n",
       "      <th>win_rate_role_don_last20</th>\n",
       "      <th>win_rate_role_black_last20</th>\n",
       "      <th>win_rate_role_sheriff_last20</th>\n",
       "      <th>win_rate_role_red_last20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>26</td>\n",
       "      <td>red</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>50</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>74</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>98</td>\n",
       "      <td>red</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id      team  player_id   role  games_in_role  \\\n",
       "0   100001  citizens          2    red              0   \n",
       "1   100001  citizens         26    red              0   \n",
       "2   100001     mafia         50  black              0   \n",
       "3   100001     mafia         74  black              0   \n",
       "4   100001  citizens         98    red              0   \n",
       "\n",
       "   win_rate_role_don_last20  win_rate_role_black_last20  \\\n",
       "0                       NaN                         NaN   \n",
       "1                       NaN                         NaN   \n",
       "2                       NaN                         NaN   \n",
       "3                       NaN                         NaN   \n",
       "4                       NaN                         NaN   \n",
       "\n",
       "   win_rate_role_sheriff_last20  win_rate_role_red_last20  \n",
       "0                           NaN                       NaN  \n",
       "1                           NaN                       NaN  \n",
       "2                           NaN                       NaN  \n",
       "3                           NaN                       NaN  \n",
       "4                           NaN                       NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_role_history_stats(df, windows=(5, 20, 50)):\n",
    "    \"\"\"\n",
    "    For each (player_id, role), compute:\n",
    "      - games_in_role: prior count before current game\n",
    "      - rolling win rates on this role using only past outcomes\n",
    "        => win_rate_role_<role>_last{W}\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['player_id', 'role', 'id']).copy()\n",
    "    out = []\n",
    "\n",
    "    for (pid, role), g in df.groupby(['player_id', 'role'], sort=False):\n",
    "        g = g.copy()\n",
    "        # Prior outcomes only\n",
    "        past = g['team_win'].shift(1)\n",
    "\n",
    "        # Experience in this role\n",
    "        g['games_in_role'] = np.arange(len(g))  # 0,1,2... before current\n",
    "\n",
    "        # Rolling, role-specific winrates\n",
    "        for w in windows:\n",
    "            g[f'win_rate_role_{role}_last{w}'] = past.rolling(w, min_periods=1).mean()\n",
    "\n",
    "        out.append(g)\n",
    "\n",
    "    return pd.concat(out, ignore_index=True).sort_values('id').reset_index(drop=True)\n",
    "\n",
    "work_players = add_role_history_stats(work_players, windows=(5,20,50))\n",
    "\n",
    "# Quick peek\n",
    "cols_preview = ['game_id','team','player_id','role','games_in_role',\n",
    "                'win_rate_role_don_last20','win_rate_role_black_last20',\n",
    "                'win_rate_role_sheriff_last20','win_rate_role_red_last20']\n",
    "existing = [c for c in cols_preview if c in work_players.columns]\n",
    "work_players[existing].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43002efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team</th>\n",
       "      <th>player_id</th>\n",
       "      <th>pre_elo</th>\n",
       "      <th>roll5_win_rate</th>\n",
       "      <th>roll20_win_rate</th>\n",
       "      <th>career_win_rate</th>\n",
       "      <th>games_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>2</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>26</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>50</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>74</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>98</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id      team  player_id  pre_elo  roll5_win_rate  roll20_win_rate  \\\n",
       "0   100001  citizens          2   1500.0             NaN              NaN   \n",
       "1   100001  citizens         26   1500.0             NaN              NaN   \n",
       "2   100001     mafia         50   1500.0             NaN              NaN   \n",
       "3   100001     mafia         74   1500.0             NaN              NaN   \n",
       "4   100001  citizens         98   1500.0             NaN              NaN   \n",
       "\n",
       "   career_win_rate  games_played  \n",
       "0              NaN             0  \n",
       "1              NaN             0  \n",
       "2              NaN             0  \n",
       "3              NaN             0  \n",
       "4              NaN             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This preview now works again:\n",
    "work_players[['game_id','team','player_id',\n",
    "              'pre_elo',\n",
    "              'roll5_win_rate','roll20_win_rate','career_win_rate','games_played']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c60d6",
   "metadata": {},
   "source": [
    "### Synergy features (co-play history)\n",
    "For each game and team, compute how many times each pair of teammates had previously played together on the **same side**. Aggregate within the team (mean, max). Uses chronological order by `id`, no leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "357fc3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team</th>\n",
       "      <th>synergy_mean_team</th>\n",
       "      <th>synergy_max_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id      team  synergy_mean_team  synergy_max_team\n",
       "0   100001  citizens                0.0               0.0\n",
       "1   100001  citizens                0.0               0.0\n",
       "2   100001     mafia                0.0               0.0\n",
       "3   100001     mafia                0.0               0.0\n",
       "4   100001  citizens                0.0               0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def add_synergy_features(df):\n",
    "    \"\"\"\n",
    "    For each game_id and team:\n",
    "      - Compute prior same-team co-plays for all unordered pairs within that team (before this game).\n",
    "      - Store team-level aggregates: synergy_mean_team, synergy_max_team.\n",
    "    Implementation detail:\n",
    "      - Iterate games in chronological order (by max id in the game).\n",
    "      - Maintain a dictionary that counts how many times pair (a,b) have co-played on a given side.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # game chronological order (by last id within game)\n",
    "    game_order = (df.groupby('game_id')['id'].max()\n",
    "                    .sort_values().index.tolist())\n",
    "\n",
    "    # dict key: (min(pid), max(pid), team) -> count of prior co-plays on that team\n",
    "    pair_counts = {}\n",
    "\n",
    "    # output rows: (game_id, team, synergy_mean, synergy_max)\n",
    "    out_rows = []\n",
    "\n",
    "    for gid in game_order:\n",
    "        g = df[df['game_id'] == gid]\n",
    "        for team in ['mafia', 'citizens']:\n",
    "            team_players = g.loc[g['team'] == team, 'player_id'].tolist()\n",
    "            pair_vals = []\n",
    "            for a, b in combinations(sorted(team_players), 2):\n",
    "                key = (a, b, team)\n",
    "                pair_vals.append(pair_counts.get(key, 0))\n",
    "\n",
    "            if len(pair_vals) == 0:\n",
    "                s_mean, s_max = 0.0, 0.0\n",
    "            else:\n",
    "                s_mean = float(np.mean(pair_vals))\n",
    "                s_max  = float(np.max(pair_vals))\n",
    "\n",
    "            out_rows.append((gid, team, s_mean, s_max))\n",
    "\n",
    "        # AFTER recording features, update counts with this game\n",
    "        for team in ['mafia', 'citizens']:\n",
    "            team_players = g.loc[g['team'] == team, 'player_id'].tolist()\n",
    "            for a, b in combinations(sorted(team_players), 2):\n",
    "                key = (a, b, team)\n",
    "                pair_counts[key] = pair_counts.get(key, 0) + 1\n",
    "\n",
    "    team_synergy = pd.DataFrame(out_rows, columns=['game_id','team','synergy_mean_team','synergy_max_team'])\n",
    "    # attach to every player-row (team-wise constant)\n",
    "    return df.merge(team_synergy, on=['game_id','team'], how='left')\n",
    "\n",
    "# AFTER: call it\n",
    "work_players = add_synergy_features(work_players)\n",
    "work_players[['game_id','team','synergy_mean_team','synergy_max_team']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c52010",
   "metadata": {},
   "source": [
    "### Streak features (momentum)\n",
    "Compute per-player **pre-game** win_streak and loss_streak using only past results. Aggregate to team (mean, max).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca2f1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>win_streak</th>\n",
       "      <th>loss_streak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id  player_id  win_streak  loss_streak\n",
       "0   100001          2           0            0\n",
       "1   100001         26           0            0\n",
       "2   100001         50           0            0\n",
       "3   100001         74           0            0\n",
       "4   100001         98           0            0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_streak_features(df):\n",
    "    \"\"\"\n",
    "    Adds per-player pre-game streaks:\n",
    "      - win_streak: consecutive wins ending just before this game\n",
    "      - loss_streak: consecutive losses ending just before this game\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['player_id','id']).copy()\n",
    "    win_streaks = []\n",
    "    loss_streaks = []\n",
    "\n",
    "    for pid, g in df.groupby('player_id', sort=False):\n",
    "        prev = g['team_win'].shift(1).values  # past outcomes only\n",
    "        w_stk = np.zeros(len(g), dtype=np.int16)\n",
    "        l_stk = np.zeros(len(g), dtype=np.int16)\n",
    "        cur_w, cur_l = 0, 0\n",
    "        for i, v in enumerate(prev):\n",
    "            if np.isnan(v):\n",
    "                cur_w, cur_l = 0, 0\n",
    "            else:\n",
    "                if v == 1:  # previous result was win\n",
    "                    cur_w += 1\n",
    "                    cur_l = 0\n",
    "                else:       # previous result was loss\n",
    "                    cur_l += 1\n",
    "                    cur_w = 0\n",
    "            w_stk[i] = cur_w\n",
    "            l_stk[i] = cur_l\n",
    "        win_streaks.append(pd.Series(w_stk, index=g.index))\n",
    "        loss_streaks.append(pd.Series(l_stk, index=g.index))\n",
    "\n",
    "    df['win_streak']  = pd.concat(win_streaks).sort_index()\n",
    "    df['loss_streak'] = pd.concat(loss_streaks).sort_index()\n",
    "    return df.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "# AFTER: call it\n",
    "work_players = add_streak_features(work_players)\n",
    "work_players[['game_id','player_id','win_streak','loss_streak']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f9478",
   "metadata": {},
   "source": [
    "### Games played to date (per player)\n",
    "Cumulative count of past games per player (pre-game). Useful as a general “experience” signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc73d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_games_played_feature(df):\n",
    "    d = df.sort_values(['player_id','id']).copy()\n",
    "    # number of *prior* appearances (shift to avoid leakage)\n",
    "    d['games_played'] = d.groupby('player_id').cumcount().astype('int32')\n",
    "    return d.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "work_players = add_games_played_feature(work_players)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55f83a",
   "metadata": {},
   "source": [
    "## Enemy familiarity (cross-team co-history)\n",
    "For each game_id: count how many times each player faced each opponent in previous games.\n",
    "Aggregate to team-level (mean/max).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91298de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def add_enemy_familiarity_features(df):\n",
    "    \"\"\"\n",
    "    For each game:\n",
    "      - For each player p in team A and q in team B, look up how many previous times p faced q on opposite teams.\n",
    "      - Aggregate per team: enemy_fam_mean_team, enemy_fam_max_team.\n",
    "    \"\"\"\n",
    "    d = df.sort_values('id').copy()\n",
    "    game_order = (d.groupby('game_id')['id'].max().sort_values().index.tolist())\n",
    "\n",
    "    faced_counts = {}  # key=(min(pid),max(pid)) -> count of prior *opposite-team* meetings\n",
    "    out_rows = []\n",
    "\n",
    "    for gid in game_order:\n",
    "        g = d[d['game_id'] == gid]\n",
    "        maf = g[g['team']=='mafia']['player_id'].dropna().astype(int).tolist()\n",
    "        cit = g[g['team']=='citizens']['player_id'].dropna().astype(int).tolist()\n",
    "\n",
    "        # current features (use counts BEFORE update)\n",
    "        pairs_maf = [faced_counts.get(tuple(sorted([a,b])), 0) for a,b in product(maf, cit)]\n",
    "        pairs_cit = [faced_counts.get(tuple(sorted([a,b])), 0) for a,b in product(cit, maf)]\n",
    "\n",
    "        def stats(vals):\n",
    "            return (float(np.mean(vals)) if vals else 0.0,\n",
    "                    float(np.max(vals))  if vals else 0.0)\n",
    "\n",
    "        maf_mean, maf_max = stats(pairs_maf)\n",
    "        cit_mean, cit_max = stats(pairs_cit)\n",
    "\n",
    "        out_rows.append((gid,'mafia',    maf_mean, maf_max))\n",
    "        out_rows.append((gid,'citizens', cit_mean, cit_max))\n",
    "\n",
    "        # AFTER computing features, update counts from this game\n",
    "        for a,b in product(maf, cit):\n",
    "            key = tuple(sorted([int(a),int(b)]))\n",
    "            faced_counts[key] = faced_counts.get(key, 0) + 1\n",
    "\n",
    "    fam = pd.DataFrame(out_rows, columns=['game_id','team','enemy_fam_mean_team','enemy_fam_max_team'])\n",
    "    return d.merge(fam, on=['game_id','team'], how='left')\n",
    "\n",
    "# === AFTER: call it in the pipeline BEFORE build_team_agg ===\n",
    "work_players = add_enemy_familiarity_features(work_players)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361bb8e1",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3327b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: ['win_streak', 'loss_streak']\n"
     ]
    }
   ],
   "source": [
    "needed = ['pre_elo','pre_elo_side','pre_elo_role','gap_id_clipped','long_break_flag',\n",
    "          'place','games_played','win_streak','loss_streak','synergy_mean_team',\n",
    "          'synergy_max_team','enemy_fam_mean_team','enemy_fam_max_team',\n",
    "          'roll5_win_rate_mafia','roll20_win_rate_mafia',\n",
    "          'roll5_win_rate_citizens','roll20_win_rate_citizens','meta_period']\n",
    "missing = [c for c in needed if c not in work_players.columns]\n",
    "print(\"Missing columns:\", missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f767901",
   "metadata": {},
   "source": [
    "## 3) Team aggregation with role history\n",
    "Aggregate role-specific player history to team-level:\n",
    "- Don & Sheriff: singletons (use their values)\n",
    "- Black/Red: means across those players\n",
    "Compute safe opponent-relative features:\n",
    "- deltas (mafia - citizens)\n",
    "- ratios ( (mafia + eps) / (citizens + eps) ), no labels included\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ce371c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team</th>\n",
       "      <th>pre_elo_mean</th>\n",
       "      <th>pre_elo_std</th>\n",
       "      <th>pre_elo_min</th>\n",
       "      <th>pre_elo_max</th>\n",
       "      <th>pre_elo_q25</th>\n",
       "      <th>pre_elo_q75</th>\n",
       "      <th>pre_elo_side_mean</th>\n",
       "      <th>pre_elo_role_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>don_wr20__delta_maf_minus_cit</th>\n",
       "      <th>don_wr20__ratio_maf_over_cit</th>\n",
       "      <th>sheriff_wr20__delta_maf_minus_cit</th>\n",
       "      <th>sheriff_wr20__ratio_maf_over_cit</th>\n",
       "      <th>black_mean_wr20__delta_maf_minus_cit</th>\n",
       "      <th>black_mean_wr20__ratio_maf_over_cit</th>\n",
       "      <th>red_mean_wr20__delta_maf_minus_cit</th>\n",
       "      <th>red_mean_wr20__ratio_maf_over_cit</th>\n",
       "      <th>game_max_id__delta_maf_minus_cit</th>\n",
       "      <th>game_max_id__ratio_maf_over_cit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>citizens</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>mafia</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>citizens</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id      team  pre_elo_mean  pre_elo_std  pre_elo_min  pre_elo_max  \\\n",
       "0   100001  citizens        1500.0          0.0       1500.0       1500.0   \n",
       "1   100001     mafia        1500.0          0.0       1500.0       1500.0   \n",
       "2   100002  citizens        1500.0          0.0       1500.0       1500.0   \n",
       "\n",
       "   pre_elo_q25  pre_elo_q75  pre_elo_side_mean  pre_elo_role_mean  ...  \\\n",
       "0       1500.0       1500.0             1500.0             1500.0  ...   \n",
       "1       1500.0       1500.0             1500.0             1500.0  ...   \n",
       "2       1500.0       1500.0             1500.0             1500.0  ...   \n",
       "\n",
       "   don_wr20__delta_maf_minus_cit  don_wr20__ratio_maf_over_cit  \\\n",
       "0                            NaN                           NaN   \n",
       "1                            NaN                           NaN   \n",
       "2                            NaN                           NaN   \n",
       "\n",
       "   sheriff_wr20__delta_maf_minus_cit  sheriff_wr20__ratio_maf_over_cit  \\\n",
       "0                                NaN                               NaN   \n",
       "1                                NaN                               NaN   \n",
       "2                                NaN                               NaN   \n",
       "\n",
       "   black_mean_wr20__delta_maf_minus_cit  black_mean_wr20__ratio_maf_over_cit  \\\n",
       "0                                   NaN                                  NaN   \n",
       "1                                   NaN                                  NaN   \n",
       "2                                   NaN                                  NaN   \n",
       "\n",
       "   red_mean_wr20__delta_maf_minus_cit  red_mean_wr20__ratio_maf_over_cit  \\\n",
       "0                                 NaN                                NaN   \n",
       "1                                 NaN                                NaN   \n",
       "2                                 NaN                                NaN   \n",
       "\n",
       "   game_max_id__delta_maf_minus_cit  game_max_id__ratio_maf_over_cit  \n",
       "0                                 0                              1.0  \n",
       "1                                 0                              1.0  \n",
       "2                                 0                              1.0  \n",
       "\n",
       "[3 rows x 130 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q25(x): return x.quantile(0.25)\n",
    "\n",
    "def q75(x): return x.quantile(0.75)\n",
    "\n",
    "def build_team_agg(work_players, add_ratios=True, ratio_eps=1e-3):\n",
    "    agg_funcs = {}\n",
    "\n",
    "    # helper to add aggregates only if the columns exist\n",
    "    def add_agg(col, funcs):\n",
    "        if col in work_players.columns:\n",
    "            agg_funcs[col] = funcs\n",
    "\n",
    "    # core blocks\n",
    "    add_agg('pre_elo', ['mean','std','min','max', q25, q75])\n",
    "    add_agg('pre_elo_side', ['mean'])\n",
    "    add_agg('pre_elo_role', ['mean'])\n",
    "    add_agg('gap_id_clipped', ['mean','max'])\n",
    "    add_agg('long_break_flag', ['sum'])\n",
    "    add_agg('place', ['mean','std','min','max'])\n",
    "    add_agg('games_played', ['mean','std','min','max'])\n",
    "\n",
    "    # optional blocks (only if present)\n",
    "    add_agg('win_streak', ['mean','max'])\n",
    "    add_agg('loss_streak', ['mean','max'])\n",
    "    add_agg('synergy_mean_team', ['mean'])\n",
    "    add_agg('synergy_max_team',  ['mean'])\n",
    "    add_agg('enemy_fam_mean_team', ['mean'])\n",
    "    add_agg('enemy_fam_max_team',  ['mean'])\n",
    "    add_agg('roll5_win_rate_mafia',  ['mean'])\n",
    "    add_agg('roll20_win_rate_mafia', ['mean'])\n",
    "    add_agg('roll5_win_rate_citizens',  ['mean'])\n",
    "    add_agg('roll20_win_rate_citizens', ['mean'])\n",
    "    \n",
    "    if 'meta_period' in work_players.columns:\n",
    "        agg_funcs['meta_period'] = ['first']\n",
    "\n",
    "    base = work_players.groupby(['game_id','team']).agg(agg_funcs)\n",
    "    base.columns = ['_'.join([c for c in map(str, col) if c and c!='<function ' and c!='>'])\n",
    "                    for col in base.columns]\n",
    "    base = base.reset_index()\n",
    "\n",
    "    # full (game_id,team) index to align role series\n",
    "    full_idx = base.set_index(['game_id','team']).index\n",
    "\n",
    "    def single_role_stat(role, value_col, out_name):\n",
    "        s = (work_players[work_players['role'] == role]\n",
    "             .groupby(['game_id','team'])[value_col].mean()).reindex(full_idx)\n",
    "        s.name = out_name\n",
    "        return s\n",
    "\n",
    "    def mean_role_stat(role, value_col, out_name):\n",
    "        s = (work_players[work_players['role'] == role]\n",
    "             .groupby(['game_id','team'])[value_col].mean()).reindex(full_idx)\n",
    "        s.name = out_name\n",
    "        return s\n",
    "\n",
    "    # Role-specific Elo & seats (as before)\n",
    "    don_elo       = single_role_stat('don',     'pre_elo_role', 'don_pre_elo_role')\n",
    "    sheriff_elo   = single_role_stat('sheriff', 'pre_elo_role', 'sheriff_pre_elo_role')\n",
    "    don_place     = single_role_stat('don',     'place',        'don_place')\n",
    "    sheriff_place = single_role_stat('sheriff', 'place',        'sheriff_place')\n",
    "    black_elo_mean= mean_role_stat('black',     'pre_elo_role', 'black_mean_pre_elo_role')\n",
    "    red_elo_mean  = mean_role_stat('red',       'pre_elo_role', 'red_mean_pre_elo_role')\n",
    "\n",
    "    # NEW — role history: games_in_role\n",
    "    don_games   = single_role_stat('don',     'games_in_role', 'don_games_in_role')\n",
    "    sheriff_games  = single_role_stat('sheriff', 'games_in_role', 'sheriff_games_in_role')\n",
    "    black_games = mean_role_stat('black',     'games_in_role', 'black_mean_games_in_role')\n",
    "    red_games   = mean_role_stat('red',       'games_in_role', 'red_mean_games_in_role')\n",
    "\n",
    "    # NEW — role history: recent role win rates (use last20 as a strong default)\n",
    "    # (You can add last5/last50 similarly if you like.)\n",
    "    don_wr20    = single_role_stat('don',     'win_rate_role_don_last20', 'don_wr20')\n",
    "    sheriff_wr20   = single_role_stat('sheriff', 'win_rate_role_sheriff_last20', 'sheriff_wr20')\n",
    "    black_wr20  = mean_role_stat('black',     'win_rate_role_black_last20', 'black_mean_wr20')\n",
    "    red_wr20    = mean_role_stat('red',       'win_rate_role_red_last20',   'red_mean_wr20')\n",
    "\n",
    "    role_feats = pd.concat(\n",
    "        [don_elo, sheriff_elo, don_place, sheriff_place, black_elo_mean, red_elo_mean,\n",
    "         don_games, sheriff_games, black_games, red_games,\n",
    "         don_wr20, sheriff_wr20, black_wr20, red_wr20],\n",
    "        axis=1\n",
    "    ).reset_index()\n",
    "\n",
    "    team_agg = base.merge(role_feats, on=['game_id','team'], how='left')\n",
    "\n",
    "    # 3) Label & time proxy\n",
    "    labels  = work_players.groupby(['game_id','team'])['team_win'].max().rename('team_win_team')\n",
    "    gmaxid  = work_players.groupby('game_id')['id'].max().rename('game_max_id')\n",
    "    team_agg = team_agg.merge(labels, on=['game_id','team']).merge(gmaxid, on='game_id')\n",
    "\n",
    "    # 4) SAFE deltas\n",
    "    wide = team_agg.pivot(index='game_id', columns='team')\n",
    "    wide.columns = [f\"{a}__{b}\" for a,b in wide.columns]\n",
    "    wide = wide.reset_index()\n",
    "\n",
    "    def side_cols(side): return [c for c in wide.columns if c.endswith(f\"__{side}\") and c != 'game_id']\n",
    "    maf_cols = side_cols('mafia')\n",
    "\n",
    "    skip_prefixes = ('team_win_team', 'meta_period')\n",
    "\n",
    "    delta = pd.DataFrame({'game_id': wide['game_id']})\n",
    "    for mcol in maf_cols:\n",
    "        if 'team_win_team' in mcol:\n",
    "            continue  # NEVER delta the target\n",
    "\n",
    "        base_name = mcol[:-len(\"__mafia\")]\n",
    "\n",
    "        if base_name.startswith(skip_prefixes):\n",
    "            continue\n",
    "\n",
    "        ccol = base_name + \"__citizens\"\n",
    "        if ccol in wide.columns:\n",
    "            delta[base_name + \"__delta_maf_minus_cit\"] = wide[mcol] - wide[ccol]\n",
    "            if add_ratios:\n",
    "                # Safe ratio to capture non-linear effects (avoid div-by-zero)\n",
    "                delta[base_name + \"__ratio_maf_over_cit\"] = (wide[mcol] + ratio_eps) / (wide[ccol] + ratio_eps)\n",
    "\n",
    "    team_tall = team_agg.merge(delta, on='game_id', how='left')\n",
    "    return team_tall\n",
    "\n",
    "# Rebuild team dataset with new role history included\n",
    "team_tall = build_team_agg(work_players, add_ratios=True)\n",
    "\n",
    "# Save aggregated dataset\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "team_tall.to_csv(OUT_DIR/\"mafia_team_agg.csv\", index=False)\n",
    "team_tall.to_parquet(OUT_DIR/\"mafia_team_agg.parquet\", index=False)\n",
    "team_tall.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c123447",
   "metadata": {},
   "source": [
    "## 4) Features, CV strategy, and baselines\n",
    "- `X`: team aggregates + delta features\n",
    "- `y`: `team_win_team`\n",
    "- `groups`: `game_id`\n",
    "- Chronological split by `game_max_id` (70/15/15) for calibration & final holdout\n",
    "- Include role-history aggregates (don/sheriff/black/red games & WR20) and generated ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d1c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_only = [c for c in team_tall.columns if c.startswith((\n",
    "    'pre_elo_', 'gap_id_clipped_', 'long_break_flag_',\n",
    "    'place_', 'win_streak_', 'loss_streak_', 'synergy_mean_team_', 'synergy_max_team_',\n",
    "    'enemy_fam_',\n",
    "    'games_played_',\n",
    "    'don_pre_elo_role', 'sheriff_pre_elo_role', 'black_mean_pre_elo_role', 'red_mean_pre_elo_role',\n",
    "    'don_games_in_role', 'sheriff_games_in_role', 'black_mean_games_in_role', 'red_mean_games_in_role',\n",
    "    'don_wr20', 'sheriff_wr20', 'black_mean_wr20', 'red_mean_wr20',\n",
    "    'meta_period_first', \n",
    "    'enemy_fam_mean_team_mean', 'enemy_fam_max_team_mean'\n",
    "))]\n",
    "\n",
    "delta_feats = [c for c in team_tall.columns if c.endswith('__delta_maf_minus_cit') or c.endswith('__ratio_maf_over_cit')]\n",
    "\n",
    "forbidden_tokens = {'team_win','team_win_team'}\n",
    "USED_FEATS = [c for c in sorted(set(team_only + delta_feats))\n",
    "              if not any(tok in c for tok in forbidden_tokens)]\n",
    "\n",
    "X = team_tall[USED_FEATS].fillna(0)\n",
    "y = team_tall['team_win_team'].astype(int).values\n",
    "groups = team_tall['game_id'].values\n",
    "time_key = team_tall['game_max_id'].values\n",
    "\n",
    "q70, q85 = np.quantile(time_key, [0.70, 0.85])\n",
    "train_mask = time_key <= q85\n",
    "cal_mask   = (time_key > q70) & (time_key <= q85)\n",
    "test_mask  = time_key > q85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77acc2f9",
   "metadata": {},
   "source": [
    "### Removing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d9e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Near-constant features: ['black_mean_games_in_role__delta_maf_minus_cit', 'black_mean_games_in_role__ratio_maf_over_cit', 'black_mean_pre_elo_role__delta_maf_minus_cit', 'black_mean_pre_elo_role__ratio_maf_over_cit', 'black_mean_wr20__delta_maf_minus_cit', 'black_mean_wr20__ratio_maf_over_cit', 'don_games_in_role__delta_maf_minus_cit', 'don_games_in_role__ratio_maf_over_cit', 'don_place__delta_maf_minus_cit', 'don_place__ratio_maf_over_cit', 'don_pre_elo_role__delta_maf_minus_cit', 'don_pre_elo_role__ratio_maf_over_cit', 'don_wr20__delta_maf_minus_cit', 'don_wr20__ratio_maf_over_cit', 'enemy_fam_max_team_mean__delta_maf_minus_cit', 'enemy_fam_max_team_mean__ratio_maf_over_cit', 'enemy_fam_mean_team_mean__delta_maf_minus_cit', 'enemy_fam_mean_team_mean__ratio_maf_over_cit', 'game_max_id__delta_maf_minus_cit', 'game_max_id__ratio_maf_over_cit', 'red_mean_games_in_role__delta_maf_minus_cit', 'red_mean_games_in_role__ratio_maf_over_cit', 'red_mean_pre_elo_role__delta_maf_minus_cit', 'red_mean_pre_elo_role__ratio_maf_over_cit', 'red_mean_wr20__delta_maf_minus_cit', 'red_mean_wr20__ratio_maf_over_cit', 'roll20_win_rate_citizens_mean__delta_maf_minus_cit', 'roll20_win_rate_citizens_mean__ratio_maf_over_cit', 'roll20_win_rate_mafia_mean__delta_maf_minus_cit', 'roll20_win_rate_mafia_mean__ratio_maf_over_cit', 'roll5_win_rate_citizens_mean__delta_maf_minus_cit', 'roll5_win_rate_citizens_mean__ratio_maf_over_cit', 'roll5_win_rate_mafia_mean__delta_maf_minus_cit', 'roll5_win_rate_mafia_mean__ratio_maf_over_cit', 'sheriff_games_in_role__delta_maf_minus_cit', 'sheriff_games_in_role__ratio_maf_over_cit', 'sheriff_place__delta_maf_minus_cit', 'sheriff_place__ratio_maf_over_cit', 'sheriff_pre_elo_role__delta_maf_minus_cit', 'sheriff_pre_elo_role__ratio_maf_over_cit', 'sheriff_wr20__delta_maf_minus_cit', 'sheriff_wr20__ratio_maf_over_cit']\n",
      "Highly collinear to drop: ['don_pre_elo_role', 'place_max__ratio_maf_over_cit', 'place_mean__ratio_maf_over_cit', 'place_min__ratio_maf_over_cit', 'place_std__ratio_maf_over_cit', 'pre_elo_max__ratio_maf_over_cit', 'pre_elo_mean__ratio_maf_over_cit', 'pre_elo_min__ratio_maf_over_cit', 'pre_elo_q25__ratio_maf_over_cit', 'pre_elo_q75__ratio_maf_over_cit', 'pre_elo_role_mean__ratio_maf_over_cit', 'pre_elo_side_mean__ratio_maf_over_cit', 'red_mean_pre_elo_role', 'sheriff_pre_elo_role', 'synergy_mean_team_mean__ratio_maf_over_cit']\n"
     ]
    }
   ],
   "source": [
    "low_var = X.columns[X.std() < 1e-6]\n",
    "print(\"Near-constant features:\", list(low_var))\n",
    "X.drop(columns=low_var, inplace=True)\n",
    "USED_FEATS = [c for c in USED_FEATS if c not in set(low_var)]\n",
    "\n",
    "corr = X[train_mask].corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "to_drop = [col for col in upper.columns if (upper[col] > 0.98).any()]\n",
    "print(\"Highly collinear to drop:\", to_drop[:20])\n",
    "X.drop(columns=to_drop, inplace=True)\n",
    "USED_FEATS = [c for c in USED_FEATS if c not in set(to_drop)]\n",
    "\n",
    "# # quick one-pass using final model (or average across folds if you saved them)\n",
    "# imp = pd.DataFrame({'feature': X.columns,\n",
    "#                     'gain': final.booster_.feature_importance(importance_type='gain')})\n",
    "# zero_imp = imp.loc[imp['gain'] == 0, 'feature'].tolist()\n",
    "# print(\"Zero-importance:\", zero_imp[:20])\n",
    "# X.drop(columns=zero_imp, inplace=True)\n",
    "# USED_FEATS = [c for c in USED_FEATS if c not in set(zero_imp)]\n",
    "\n",
    "\n",
    "ratio_cols = [c for c in X.columns if c.endswith('__ratio_maf_over_cit')]\n",
    "X = X.drop(columns=ratio_cols)\n",
    "USED_FEATS = [c for c in USED_FEATS if c not in set(ratio_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b8985d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 74\n",
      "Rows: 160564 | Train: 136480 Cal: 24084 Test: 24084\n"
     ]
    }
   ],
   "source": [
    "print(\"Features:\", len(USED_FEATS))\n",
    "print(\"Rows:\", len(team_tall), \"| Train:\", train_mask.sum(), \"Cal:\", cal_mask.sum(), \"Test:\", test_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a2428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baseline-0 constant 0.5 on holdout\n",
    "# p_const = np.repeat(0.5, len(y))\n",
    "# print(\"Baseline-0 (holdout) LogLoss:\", log_loss(y[test_mask], p_const[test_mask]))\n",
    "# print(\"Baseline-0 (holdout) Brier  :\", brier_score_loss(y[test_mask], p_const[test_mask]))\n",
    "# # ROC-AUC is undefined for a constant predictor; skip.\n",
    "\n",
    "# # Baseline-1 Logistic Regression with GroupKFold\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# logreg = Pipeline([\n",
    "#     ('scaler', StandardScaler(with_mean=True)),  # center & scale (X is dense)\n",
    "#     ('lr', LogisticRegression(\n",
    "#         max_iter=5000,          # more steps\n",
    "#         solver='lbfgs',         # good default for L2\n",
    "#         penalty='l2',\n",
    "#         n_jobs=-1,\n",
    "#         random_state=SEED\n",
    "#     ))\n",
    "# ])\n",
    "\n",
    "# gkf = GroupKFold(n_splits=5)\n",
    "# lls, aucs, brs = [], [], []\n",
    "# for tr, va in gkf.split(X, y, groups=groups):\n",
    "#     logreg.fit(X.iloc[tr], y[tr])\n",
    "#     p = logreg.predict_proba(X.iloc[va])[:,1]\n",
    "#     lls.append(log_loss(y[va], p))\n",
    "#     aucs.append(roc_auc_score(y[va], p))\n",
    "#     brs.append(brier_score_loss(y[va], p))\n",
    "# print(f\"Baseline-1 (LogReg) | LogLoss {np.mean(lls):.4f}±{np.std(lls):.4f} | \"\n",
    "#       f\"AUC {np.mean(aucs):.4f}±{np.std(aucs):.4f} | Brier {np.mean(brs):.4f}±{np.std(brs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f702014",
   "metadata": {},
   "source": [
    "## Sanity checks (quick)\n",
    "- No forbidden features (label-like) in `USED_FEATS`.\n",
    "- team_tall has exactly 2 rows per game.\n",
    "- New columns present and not all-NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "754a3784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forbidden features found: []\n",
      "Rows per game: 2    80282\n",
      "Name: count, dtype: int64\n",
      "{'don_games_in_role': np.float64(0.5001557011534341), 'sheriff_games_in_role': np.float64(0.5009155227821928), 'black_mean_games_in_role': np.float64(0.5), 'red_mean_games_in_role': np.float64(0.5), 'don_wr20': np.float64(0.7994257741461349), 'sheriff_wr20': np.float64(0.8006651553274706), 'black_mean_wr20': np.float64(0.6162153409232456), 'red_mean_wr20': np.float64(0.5348085498617374)}\n"
     ]
    }
   ],
   "source": [
    "suspects = {'team_win','team_win_team'}\n",
    "bad = [c for c in USED_FEATS if any(s in c for s in suspects)]\n",
    "print(\"Forbidden features found:\", bad)\n",
    "\n",
    "rows_per_game = team_tall.groupby('game_id').size().value_counts().head()\n",
    "print(\"Rows per game:\", rows_per_game)\n",
    "\n",
    "new_cols = ['don_games_in_role','sheriff_games_in_role','black_mean_games_in_role','red_mean_games_in_role',\n",
    "            'don_wr20','sheriff_wr20','black_mean_wr20','red_mean_wr20']\n",
    "print({c: team_tall[c].isna().mean() if c in team_tall.columns else 'missing' for c in new_cols})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad3017b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enemy_fam_mean_team_mean</th>\n",
       "      <td>160564.0</td>\n",
       "      <td>1.011147e+00</td>\n",
       "      <td>1.246545e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.238095e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enemy_fam_max_team_mean</th>\n",
       "      <td>160564.0</td>\n",
       "      <td>2.449976e+00</td>\n",
       "      <td>2.098054e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enemy_fam_mean_team_mean__delta_maf_minus_cit</th>\n",
       "      <td>160564.0</td>\n",
       "      <td>-1.226428e-17</td>\n",
       "      <td>1.140965e-16</td>\n",
       "      <td>-1.776357e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.776357e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enemy_fam_mean_team_mean__ratio_maf_over_cit</th>\n",
       "      <td>160564.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.047574e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enemy_fam_max_team_mean__delta_maf_minus_cit</th>\n",
       "      <td>160564.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enemy_fam_max_team_mean__ratio_maf_over_cit</th>\n",
       "      <td>160564.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  count          mean  \\\n",
       "enemy_fam_mean_team_mean                       160564.0  1.011147e+00   \n",
       "enemy_fam_max_team_mean                        160564.0  2.449976e+00   \n",
       "enemy_fam_mean_team_mean__delta_maf_minus_cit  160564.0 -1.226428e-17   \n",
       "enemy_fam_mean_team_mean__ratio_maf_over_cit   160564.0  1.000000e+00   \n",
       "enemy_fam_max_team_mean__delta_maf_minus_cit   160564.0  0.000000e+00   \n",
       "enemy_fam_max_team_mean__ratio_maf_over_cit    160564.0  1.000000e+00   \n",
       "\n",
       "                                                        std           min  \\\n",
       "enemy_fam_mean_team_mean                       1.246545e+00  0.000000e+00   \n",
       "enemy_fam_max_team_mean                        2.098054e+00  0.000000e+00   \n",
       "enemy_fam_mean_team_mean__delta_maf_minus_cit  1.140965e-16 -1.776357e-15   \n",
       "enemy_fam_mean_team_mean__ratio_maf_over_cit   7.047574e-17  1.000000e+00   \n",
       "enemy_fam_max_team_mean__delta_maf_minus_cit   0.000000e+00  0.000000e+00   \n",
       "enemy_fam_max_team_mean__ratio_maf_over_cit    0.000000e+00  1.000000e+00   \n",
       "\n",
       "                                                    25%      50%       75%  \\\n",
       "enemy_fam_mean_team_mean                       0.190476  0.52381  1.333333   \n",
       "enemy_fam_max_team_mean                        1.000000  2.00000  3.000000   \n",
       "enemy_fam_mean_team_mean__delta_maf_minus_cit  0.000000  0.00000  0.000000   \n",
       "enemy_fam_mean_team_mean__ratio_maf_over_cit   1.000000  1.00000  1.000000   \n",
       "enemy_fam_max_team_mean__delta_maf_minus_cit   0.000000  0.00000  0.000000   \n",
       "enemy_fam_max_team_mean__ratio_maf_over_cit    1.000000  1.00000  1.000000   \n",
       "\n",
       "                                                        max  \n",
       "enemy_fam_mean_team_mean                       1.238095e+01  \n",
       "enemy_fam_max_team_mean                        2.800000e+01  \n",
       "enemy_fam_mean_team_mean__delta_maf_minus_cit  1.776357e-15  \n",
       "enemy_fam_mean_team_mean__ratio_maf_over_cit   1.000000e+00  \n",
       "enemy_fam_max_team_mean__delta_maf_minus_cit   0.000000e+00  \n",
       "enemy_fam_max_team_mean__ratio_maf_over_cit    1.000000e+00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm they made it into USED_FEATS\n",
    "[f for f in USED_FEATS if f.startswith('enemy_fam_')][:10]\n",
    "\n",
    "# check they aren't mostly missing\n",
    "{c: float(team_tall[c].isna().mean()) for c in team_tall.columns if c.startswith('enemy_fam_')}\n",
    "\n",
    "# quick distribution look\n",
    "team_tall[[c for c in team_tall.columns if c.startswith('enemy_fam_')]].describe().T.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e92f984",
   "metadata": {},
   "source": [
    "## 5) LightGBM (main model) + CV + calibration + holdout\n",
    "### Model tuning (LightGBM)\n",
    "Slightly higher capacity + early stopping + class_weight='balanced'. Calibrate with sigmoid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9e2da86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 64225, number of negative: 64225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11007\n",
      "[LightGBM] [Info] Number of data points in the train set: 128450, number of used features: 74\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's binary_logloss: 0.683975\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Fold 1: LogLoss=0.6840 AUC=0.5758 Brier=0.2454\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 64225, number of negative: 64225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10989\n",
      "[LightGBM] [Info] Number of data points in the train set: 128450, number of used features: 74\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's binary_logloss: 0.684974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Fold 2: LogLoss=0.6850 AUC=0.5711 Brier=0.2459\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 64226, number of negative: 64226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11016\n",
      "[LightGBM] [Info] Number of data points in the train set: 128452, number of used features: 74\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's binary_logloss: 0.684648\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Fold 3: LogLoss=0.6846 AUC=0.5738 Brier=0.2458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 64226, number of negative: 64226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11003\n",
      "[LightGBM] [Info] Number of data points in the train set: 128452, number of used features: 74\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's binary_logloss: 0.684597\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Fold 4: LogLoss=0.6846 AUC=0.5744 Brier=0.2457\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 64226, number of negative: 64226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11016\n",
      "[LightGBM] [Info] Number of data points in the train set: 128452, number of used features: 74\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[348]\tvalid_0's binary_logloss: 0.681384\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "Fold 5: LogLoss=0.6814 AUC=0.5872 Brier=0.2441\n",
      "\n",
      "CV | LogLoss 0.6839±0.0013 | AUC 0.5764±0.0056 | Brier 0.2454±0.0006\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[287]\tvalid_0's binary_logloss: 0.684246\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\data_analysis\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "\n",
      "Holdout (last 15%)\n",
      "LogLoss: 0.6815780998533566\n",
      "ROC-AUC: 0.5906308419342025\n",
      "Brier  : 0.24417794955717503\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import numpy as np\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=127,\n",
    "    min_data_in_leaf=40,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.5,\n",
    "    reg_alpha=0.3,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "lls, aucs, brs = [], [], []\n",
    "for k,(tr,va) in enumerate(gkf.split(X,y,groups=groups),1):\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(\n",
    "    X.iloc[tr], y[tr],\n",
    "    eval_set=[(X.iloc[va], y[va])],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=100),  # same meaning as early_stopping_rounds\n",
    "        log_evaluation(0)                     # silences per-iteration logs; use log_evaluation(50) to see progress\n",
    "    ]\n",
    ")\n",
    "    p = model.predict_proba(X.iloc[va])[:,1]\n",
    "    lls.append(log_loss(y[va], p)); aucs.append(roc_auc_score(y[va], p)); brs.append(brier_score_loss(y[va], p))\n",
    "    print(f\"Fold {k}: LogLoss={lls[-1]:.4f} AUC={aucs[-1]:.4f} Brier={brs[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\nCV | LogLoss {np.mean(lls):.4f}±{np.std(lls):.4f} | \"\n",
    "      f\"AUC {np.mean(aucs):.4f}±{np.std(aucs):.4f} | Brier {np.mean(brs):.4f}±{np.std(brs):.4f}\")\n",
    "\n",
    "q70, q85 = np.quantile(time_key, [0.70, 0.85])\n",
    "train_mask = time_key <= q85\n",
    "cal_mask   = (time_key > q70) & (time_key <= q85)\n",
    "test_mask  = time_key > q85\n",
    "\n",
    "# make a tiny val split from the train window (e.g., last 10% by time among train_mask)\n",
    "tr_time = time_key[train_mask]\n",
    "tr_q90 = np.quantile(tr_time, 0.90)\n",
    "inner_tr = train_mask & (time_key <= tr_q90)\n",
    "inner_va = train_mask & (time_key >  tr_q90)\n",
    "\n",
    "final = LGBMClassifier(**params)\n",
    "final.fit(\n",
    "    X[inner_tr], y[inner_tr],\n",
    "    eval_set=[(X[inner_va], y[inner_va])],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[early_stopping(stopping_rounds=100), log_evaluation(0)]\n",
    ")\n",
    "\n",
    "\n",
    "calibrated = CalibratedClassifierCV(final, cv='prefit', method='sigmoid').fit(X[cal_mask], y[cal_mask])\n",
    "\n",
    "p_test = calibrated.predict_proba(X[test_mask])[:,1]\n",
    "print(\"\\nHoldout (last 15%)\")\n",
    "print(\"LogLoss:\", log_loss(y[test_mask], p_test))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y[test_mask], p_test))\n",
    "print(\"Brier  :\", brier_score_loss(y[test_mask], p_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e41f1",
   "metadata": {},
   "source": [
    "## Calibration diagnostics\n",
    "Reliability curve and ECE to assess probability quality on holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4138a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE (10 bins): 0.0184\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "def expected_calibration_error(y_true, y_prob, n_bins=10):\n",
    "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
    "    inds = np.digitize(y_prob, bins) - 1\n",
    "    ece = 0.0\n",
    "    for b in range(n_bins):\n",
    "        mask = inds == b\n",
    "        if mask.sum() == 0: \n",
    "            continue\n",
    "        conf = y_prob[mask].mean()\n",
    "        acc  = y_true[mask].mean()\n",
    "        ece += (mask.mean()) * abs(acc - conf)\n",
    "    return ece\n",
    "\n",
    "p_test = p_test if 'p_test' in locals() else calibrated.predict_proba(X[test_mask])[:,1]\n",
    "ece = expected_calibration_error(y[test_mask], p_test, n_bins=10)\n",
    "print(f\"ECE (10 bins): {ece:.4f}\")\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y[test_mask], p_test, n_bins=10)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(prob_pred, prob_true, 'o-')\n",
    "plt.plot([0,1],[0,1],'--', alpha=0.6)\n",
    "plt.xlabel('Predicted probability'); plt.ylabel('Observed frequency')\n",
    "plt.title('Reliability curve (holdout)')\n",
    "plt.grid(alpha=0.2); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c7d22f",
   "metadata": {},
   "source": [
    "## Experiment: Elo decay constant τ sweep\n",
    "We rebuild the feature pipeline for several τ values and compare holdout metrics to pick the best τ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af84f2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Info] Number of positive: 68240, number of negative: 68240\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8890\n",
      "[LightGBM] [Info] Number of data points in the train set: 136480, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\data_analysis\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "tau=400  AUC=0.5911  LogLoss=0.6939\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Info] Number of positive: 68240, number of negative: 68240\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8890\n",
      "[LightGBM] [Info] Number of data points in the train set: 136480, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\data_analysis\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "tau=800  AUC=0.5906  LogLoss=0.6942\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Info] Number of positive: 68240, number of negative: 68240\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8890\n",
      "[LightGBM] [Info] Number of data points in the train set: 136480, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\data_analysis\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "tau=1200  AUC=0.5903  LogLoss=0.6942\n",
      "Best tau: (0.5911269774909778, 0.693871851259183, 400.0)\n"
     ]
    }
   ],
   "source": [
    "best = None\n",
    "for tau in [400.0, 800.0, 1200.0]:\n",
    "    work_players = compute_elos(df, init=1500, k=24, tau=tau)\n",
    "    # re-run your feature builders here (rolling/break/best_move if any, synergy, enemy fam, role history)\n",
    "    work_players = add_rolling_stats_side(work_players)\n",
    "    work_players = add_break_features(work_players, GAP_THRESH)\n",
    "    work_players = add_role_history_stats(work_players, windows=(5,20,50))\n",
    "    work_players = add_synergy_features(work_players)\n",
    "    work_players = add_enemy_familiarity_features(work_players)\n",
    "    team_tall    = build_team_agg(work_players, add_ratios=False)  # we dropped ratios globally\n",
    "\n",
    "    # select features (reuse your selection code but without ratios)\n",
    "    team_only = [c for c in team_tall.columns if c.startswith((\n",
    "        'pre_elo_', 'gap_id_clipped_', 'long_break_flag_', 'place_',\n",
    "        'win_streak_', 'loss_streak_', 'synergy_mean_team_', 'synergy_max_team_',\n",
    "        'enemy_fam_', 'games_played_',\n",
    "        'don_pre_elo_role','sheriff_pre_elo_role','black_mean_pre_elo_role','red_mean_pre_elo_role',\n",
    "        'don_games_in_role','sheriff_games_in_role','black_mean_games_in_role','red_mean_games_in_role',\n",
    "        'don_wr20','sheriff_wr20','black_mean_wr20','red_mean_wr20','meta_period_first'\n",
    "    ))]\n",
    "    delta_feats = [c for c in team_tall.columns if c.endswith('__delta_maf_minus_cit')]\n",
    "    USED = [c for c in sorted(set(team_only + delta_feats)) if 'team_win' not in c]\n",
    "\n",
    "    Xg = team_tall[USED].fillna(0); yg = team_tall['team_win_team'].astype(int).values\n",
    "    tg = team_tall['game_max_id'].values\n",
    "    q70,q85 = np.quantile(tg,[0.70,0.85]); Tr = tg<=q85; Cal=(tg>q70)&(tg<=q85); Te=tg>q85\n",
    "\n",
    "    m = LGBMClassifier(**best_params if 'best_params' in globals() else dict(\n",
    "        n_estimators=1200, learning_rate=0.01, num_leaves=127, min_data_in_leaf=60,\n",
    "        subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0, reg_alpha=0.5,\n",
    "        class_weight='balanced', random_state=42, n_jobs=-1))\n",
    "    m.fit(Xg[Tr], yg[Tr])\n",
    "    cal = CalibratedClassifierCV(m, cv='prefit', method='sigmoid').fit(Xg[Cal], yg[Cal])\n",
    "    pt = cal.predict_proba(Xg[Te])[:,1]\n",
    "    auc = roc_auc_score(yg[Te], pt); ll = log_loss(yg[Te], pt)\n",
    "    print(f\"tau={tau:.0f}  AUC={auc:.4f}  LogLoss={ll:.4f}\")\n",
    "    if best is None or auc > best[0]:\n",
    "        best = (auc, ll, tau)\n",
    "\n",
    "print(\"Best tau:\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e40563",
   "metadata": {},
   "source": [
    "## CatBoost baseline (optional)\n",
    "A strong tabular model complementary to LightGBM. We'll train on the same splits and compare holdout metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45600cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6895594\ttest: 0.6895595\tbest: 0.6895595 (0)\ttotal: 208ms\tremaining: 8m 39s\n",
      "200:\tlearn: 0.6025043\ttest: 0.6024494\tbest: 0.6024494 (200)\ttotal: 7.65s\tremaining: 1m 27s\n",
      "400:\tlearn: 0.5986441\ttest: 0.5989709\tbest: 0.5989709 (400)\ttotal: 14.7s\tremaining: 1m 16s\n",
      "600:\tlearn: 0.5946972\ttest: 0.5951594\tbest: 0.5951594 (600)\ttotal: 22.3s\tremaining: 1m 10s\n",
      "800:\tlearn: 0.5904542\ttest: 0.5909762\tbest: 0.5909762 (800)\ttotal: 29.3s\tremaining: 1m 2s\n",
      "1000:\tlearn: 0.5859827\ttest: 0.5865223\tbest: 0.5865223 (1000)\ttotal: 36.3s\tremaining: 54.4s\n",
      "1200:\tlearn: 0.5815127\ttest: 0.5820509\tbest: 0.5820509 (1200)\ttotal: 43.9s\tremaining: 47.5s\n",
      "1400:\tlearn: 0.5772884\ttest: 0.5779059\tbest: 0.5779059 (1400)\ttotal: 51s\tremaining: 40s\n",
      "1600:\tlearn: 0.5730020\ttest: 0.5736640\tbest: 0.5736640 (1600)\ttotal: 58.1s\tremaining: 32.6s\n",
      "1800:\tlearn: 0.5689406\ttest: 0.5696475\tbest: 0.5696475 (1800)\ttotal: 1m 5s\tremaining: 25.4s\n",
      "2000:\tlearn: 0.5650575\ttest: 0.5657131\tbest: 0.5657131 (2000)\ttotal: 1m 12s\tremaining: 18.1s\n",
      "2200:\tlearn: 0.5611768\ttest: 0.5617953\tbest: 0.5617953 (2200)\ttotal: 1m 19s\tremaining: 10.8s\n",
      "2400:\tlearn: 0.5574082\ttest: 0.5580115\tbest: 0.5580115 (2400)\ttotal: 1m 27s\tremaining: 3.59s\n",
      "2499:\tlearn: 0.5554922\ttest: 0.5561259\tbest: 0.5561259 (2499)\ttotal: 1m 30s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5561258633\n",
      "bestIteration = 2499\n",
      "\n",
      "\n",
      "CatBoost — Holdout\n",
      "LogLoss: 0.7564339428403973\n",
      "ROC-AUC: 0.588254719178772\n",
      "Brier  : 0.27835867839427414\n"
     ]
    }
   ],
   "source": [
    "# Optional: if not installed, run in terminal: pip install catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# pick features and cat columns for CatBoost\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_cal,   y_cal   = X[cal_mask],   y[cal_mask]\n",
    "X_test,  y_test  = X[test_mask],  y[test_mask]\n",
    "\n",
    "cat_features = []\n",
    "if 'meta_period_mean' in X.columns:\n",
    "    cat_features.append(X.columns.get_loc('meta_period_mean'))\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_features or None)\n",
    "cal_pool   = Pool(X_cal,   y_cal,   cat_features=cat_features or None)\n",
    "test_pool  = Pool(X_test,  y_test,  cat_features=cat_features or None)\n",
    "\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=2500,\n",
    "    learning_rate=0.02,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=3.0,\n",
    "    random_seed=42,\n",
    "    eval_metric='Logloss',\n",
    "    loss_function='Logloss',\n",
    "    class_weights=[1.0, 2.3],  # adjust for imbalance\n",
    "    use_best_model=True,\n",
    "    verbose=200\n",
    ")\n",
    "cat.fit(train_pool, eval_set=cal_pool)\n",
    "p_test_cat = cat.predict_proba(test_pool)[:,1]\n",
    "\n",
    "print(\"\\nCatBoost — Holdout\")\n",
    "print(\"LogLoss:\", log_loss(y_test, p_test_cat))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, p_test_cat))\n",
    "print(\"Brier  :\", brier_score_loss(y_test, p_test_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0797f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "# freeze the fitted cat model for calibration\n",
    "cat_cal = CalibratedClassifierCV(cat, cv='prefit', method='sigmoid').fit(X[cal_mask], y[cal_mask])\n",
    "\n",
    "p_test_cat_cal = cat_cal.predict_proba(X[test_mask])[:,1]\n",
    "\n",
    "# compare\n",
    "print(\"\\nCatBoost Calibrated — Holdout\")\n",
    "print(\"LogLoss:\", log_loss(y[test_mask], p_test_cat_cal))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y[test_mask], p_test_cat_cal))\n",
    "print(\"Brier  :\", brier_score_loss(y[test_mask], p_test_cat_cal))\n",
    "\n",
    "# simple blend\n",
    "p_blend = 0.5 * p_test + 0.5 * p_test_cat_cal   # p_test is calibrated LGBM\n",
    "print(\"\\nBlend(0.5·LGBM + 0.5·Cat) — Holdout\")\n",
    "print(\"LogLoss:\", log_loss(y[test_mask], p_blend))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y[test_mask], p_blend))\n",
    "print(\"Brier  :\", brier_score_loss(y[test_mask], p_blend))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c448f0c",
   "metadata": {},
   "source": [
    "### Feature cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6e0ecce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black_mean_pre_elo_role</td>\n",
       "      <td>83985.988385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>red_mean_games_in_role</td>\n",
       "      <td>13423.527174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>pre_elo_side_mean__delta_maf_minus_cit</td>\n",
       "      <td>13142.434599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>place_std__delta_maf_minus_cit</td>\n",
       "      <td>10243.898983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>pre_elo_role_mean__delta_maf_minus_cit</td>\n",
       "      <td>10020.883934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>pre_elo_min__delta_maf_minus_cit</td>\n",
       "      <td>9055.357470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gap_id_clipped_max__ratio_maf_over_cit</td>\n",
       "      <td>8689.043122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>pre_elo_role_mean</td>\n",
       "      <td>8649.423267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>pre_elo_q25__delta_maf_minus_cit</td>\n",
       "      <td>8436.906132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pre_elo_max</td>\n",
       "      <td>8414.286989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>pre_elo_q75</td>\n",
       "      <td>7965.181652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>pre_elo_max__delta_maf_minus_cit</td>\n",
       "      <td>7867.533641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>pre_elo_q75__delta_maf_minus_cit</td>\n",
       "      <td>7705.502644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gap_id_clipped_mean__delta_maf_minus_cit</td>\n",
       "      <td>7611.195827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>pre_elo_std</td>\n",
       "      <td>7579.024785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature          gain\n",
       "1                    black_mean_pre_elo_role  83985.988385\n",
       "59                    red_mean_games_in_role  13423.527174\n",
       "55    pre_elo_side_mean__delta_maf_minus_cit  13142.434599\n",
       "41            place_std__delta_maf_minus_cit  10243.898983\n",
       "53    pre_elo_role_mean__delta_maf_minus_cit  10020.883934\n",
       "47          pre_elo_min__delta_maf_minus_cit   9055.357470\n",
       "21    gap_id_clipped_max__ratio_maf_over_cit   8689.043122\n",
       "52                         pre_elo_role_mean   8649.423267\n",
       "49          pre_elo_q25__delta_maf_minus_cit   8436.906132\n",
       "42                               pre_elo_max   8414.286989\n",
       "50                               pre_elo_q75   7965.181652\n",
       "43          pre_elo_max__delta_maf_minus_cit   7867.533641\n",
       "51          pre_elo_q75__delta_maf_minus_cit   7705.502644\n",
       "23  gap_id_clipped_mean__delta_maf_minus_cit   7611.195827\n",
       "56                               pre_elo_std   7579.024785"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fi = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'gain': final.booster_.feature_importance(importance_type='gain')\n",
    "}).sort_values('gain', ascending=False)\n",
    "fi.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea47672",
   "metadata": {},
   "source": [
    "## Optuna tuning (small)\n",
    "Search a handful of LightGBM hyperparameters for better logloss on a validation split drawn from the train window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e107b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\data_analysis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-10-10 17:31:11,909] A new study created in memory with name: no-name-7a2b0421-fa09-4829-a528-74301248c5ef\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:32:02,752] Trial 0 finished with value: 0.6946246238444234 and parameters: {'n_estimators': 2000, 'learning_rate': 0.017965789759657957, 'num_leaves': 175, 'min_data_in_leaf': 30, 'subsample': 0.8632443354753648, 'colsample_bytree': 0.9026991566091438, 'reg_lambda': 0.7966739646236307, 'reg_alpha': 0.4620496367691833}. Best is trial 0 with value: 0.6946246238444234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:33:42,881] Trial 1 finished with value: 0.6910782839315014 and parameters: {'n_estimators': 3000, 'learning_rate': 0.006511099303578196, 'num_leaves': 191, 'min_data_in_leaf': 100, 'subsample': 0.9030256770853151, 'colsample_bytree': 0.9309451416823362, 'reg_lambda': 1.3576600781387818, 'reg_alpha': 2.355864075146791}. Best is trial 1 with value: 0.6910782839315014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:34:23,858] Trial 2 finished with value: 0.6872414176576901 and parameters: {'n_estimators': 1600, 'learning_rate': 0.0071479455214853785, 'num_leaves': 143, 'min_data_in_leaf': 40, 'subsample': 0.7400226206959274, 'colsample_bytree': 0.8978503653085641, 'reg_lambda': 2.9338706519146625, 'reg_alpha': 0.9343110171205256}. Best is trial 2 with value: 0.6872414176576901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:35:01,271] Trial 3 finished with value: 0.6904830154063281 and parameters: {'n_estimators': 1600, 'learning_rate': 0.016485228562231283, 'num_leaves': 127, 'min_data_in_leaf': 110, 'subsample': 0.7860886646986935, 'colsample_bytree': 0.8302685706514125, 'reg_lambda': 0.09856498757226073, 'reg_alpha': 2.815827630672395}. Best is trial 2 with value: 0.6872414176576901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:35:21,592] Trial 4 finished with value: 0.6861639745299829 and parameters: {'n_estimators': 1200, 'learning_rate': 0.011593410016254939, 'num_leaves': 79, 'min_data_in_leaf': 100, 'subsample': 0.829257245782629, 'colsample_bytree': 0.9092587213962877, 'reg_lambda': 0.45888549632286146, 'reg_alpha': 1.6119769925525702}. Best is trial 4 with value: 0.6861639745299829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:36:12,005] Trial 5 finished with value: 0.6863473913314309 and parameters: {'n_estimators': 1400, 'learning_rate': 0.005417003646173663, 'num_leaves': 175, 'min_data_in_leaf': 50, 'subsample': 0.8004668745597411, 'colsample_bytree': 0.9639816477324334, 'reg_lambda': 1.5784155066329606, 'reg_alpha': 1.9114754332169688}. Best is trial 4 with value: 0.6861639745299829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:37:58,379] Trial 6 finished with value: 0.6895432771748213 and parameters: {'n_estimators': 3200, 'learning_rate': 0.006942922717297027, 'num_leaves': 143, 'min_data_in_leaf': 120, 'subsample': 0.7479753642885805, 'colsample_bytree': 0.7263797943108581, 'reg_lambda': 1.3471040187637375, 'reg_alpha': 1.6002099342067453}. Best is trial 4 with value: 0.6861639745299829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:39:09,091] Trial 7 finished with value: 0.6893030517778277 and parameters: {'n_estimators': 2400, 'learning_rate': 0.0064722500018125064, 'num_leaves': 207, 'min_data_in_leaf': 100, 'subsample': 0.8588348929519485, 'colsample_bytree': 0.8143081463940149, 'reg_lambda': 2.05384268001337, 'reg_alpha': 0.7416468066803069}. Best is trial 4 with value: 0.6861639745299829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:39:40,403] Trial 8 finished with value: 0.6883347383121106 and parameters: {'n_estimators': 1400, 'learning_rate': 0.012784058501713054, 'num_leaves': 127, 'min_data_in_leaf': 120, 'subsample': 0.7880948913810106, 'colsample_bytree': 0.9182818376404835, 'reg_lambda': 2.2155904580368633, 'reg_alpha': 2.840701900500785}. Best is trial 4 with value: 0.6861639745299829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:40:21,855] Trial 9 finished with value: 0.6945821944569877 and parameters: {'n_estimators': 2600, 'learning_rate': 0.021699063138672942, 'num_leaves': 79, 'min_data_in_leaf': 100, 'subsample': 0.9900844542331435, 'colsample_bytree': 0.7405334712996994, 'reg_lambda': 1.1376236944791618, 'reg_alpha': 1.0503793620034316}. Best is trial 4 with value: 0.6861639745299829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:41:31,029] Trial 10 finished with value: 0.7176777423435953 and parameters: {'n_estimators': 2000, 'learning_rate': 0.029918948161721713, 'num_leaves': 255, 'min_data_in_leaf': 70, 'subsample': 0.9363319017873359, 'colsample_bytree': 0.7960140601170906, 'reg_lambda': 0.10738233343028986, 'reg_alpha': 0.15076475317731175}. Best is trial 4 with value: 0.6861639745299829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:41:52,752] Trial 11 finished with value: 0.6854539589871894 and parameters: {'n_estimators': 1200, 'learning_rate': 0.009525319821443211, 'num_leaves': 63, 'min_data_in_leaf': 60, 'subsample': 0.810004385774661, 'colsample_bytree': 0.9912082139228305, 'reg_lambda': 0.6041350090343843, 'reg_alpha': 1.7703187049908027}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:42:10,857] Trial 12 finished with value: 0.685548442005242 and parameters: {'n_estimators': 1200, 'learning_rate': 0.009481695978701141, 'num_leaves': 63, 'min_data_in_leaf': 70, 'subsample': 0.8205782045048107, 'colsample_bytree': 0.9977582484476154, 'reg_lambda': 0.5333071686358678, 'reg_alpha': 1.9928554149550564}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:42:34,145] Trial 13 finished with value: 0.6855699741818715 and parameters: {'n_estimators': 1200, 'learning_rate': 0.009625944182200207, 'num_leaves': 63, 'min_data_in_leaf': 70, 'subsample': 0.7074280699623001, 'colsample_bytree': 0.994358951041993, 'reg_lambda': 0.6543536389960545, 'reg_alpha': 2.1756285127066586}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:43:14,058] Trial 14 finished with value: 0.6875861841323119 and parameters: {'n_estimators': 1800, 'learning_rate': 0.00906552165709129, 'num_leaves': 95, 'min_data_in_leaf': 60, 'subsample': 0.8249775418293589, 'colsample_bytree': 0.9990940313069375, 'reg_lambda': 0.8873499123930381, 'reg_alpha': 1.3193628982161623}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:43:42,063] Trial 15 finished with value: 0.6864947671995209 and parameters: {'n_estimators': 1200, 'learning_rate': 0.009319540674957648, 'num_leaves': 111, 'min_data_in_leaf': 80, 'subsample': 0.8943060858306945, 'colsample_bytree': 0.9646936167395734, 'reg_lambda': 0.4000562880836497, 'reg_alpha': 2.3063641376159}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:44:05,995] Trial 16 finished with value: 0.6868965837342117 and parameters: {'n_estimators': 1600, 'learning_rate': 0.012444135108549317, 'num_leaves': 63, 'min_data_in_leaf': 80, 'subsample': 0.7550902778329385, 'colsample_bytree': 0.861556261795767, 'reg_lambda': 1.851454839909664, 'reg_alpha': 1.8967860264106489}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:44:47,763] Trial 17 finished with value: 0.6874450846755474 and parameters: {'n_estimators': 2200, 'learning_rate': 0.008431323604247734, 'num_leaves': 95, 'min_data_in_leaf': 20, 'subsample': 0.8929607501577335, 'colsample_bytree': 0.9522343483618647, 'reg_lambda': 1.0155859086480392, 'reg_alpha': 1.3367950195567257}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:46:21,673] Trial 18 finished with value: 0.6937391564837345 and parameters: {'n_estimators': 1800, 'learning_rate': 0.014212087231831315, 'num_leaves': 223, 'min_data_in_leaf': 50, 'subsample': 0.8335976113063307, 'colsample_bytree': 0.8655515265239156, 'reg_lambda': 0.3948759387299015, 'reg_alpha': 1.9489356673588052}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:47:03,081] Trial 19 finished with value: 0.6877785247216013 and parameters: {'n_estimators': 2600, 'learning_rate': 0.01094343012885043, 'num_leaves': 63, 'min_data_in_leaf': 80, 'subsample': 0.9409439603593309, 'colsample_bytree': 0.7680622808076036, 'reg_lambda': 2.8073586185531614, 'reg_alpha': 2.613719552138554}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:47:30,839] Trial 20 finished with value: 0.6858943431361021 and parameters: {'n_estimators': 1400, 'learning_rate': 0.008191716994277818, 'num_leaves': 95, 'min_data_in_leaf': 60, 'subsample': 0.8080141236238088, 'colsample_bytree': 0.9826728228940315, 'reg_lambda': 0.011747576528400305, 'reg_alpha': 2.569552357817997}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:47:50,763] Trial 21 finished with value: 0.6856606800446744 and parameters: {'n_estimators': 1200, 'learning_rate': 0.010242035936575399, 'num_leaves': 63, 'min_data_in_leaf': 70, 'subsample': 0.7102732275413681, 'colsample_bytree': 0.9937390633778533, 'reg_lambda': 0.6848402041259016, 'reg_alpha': 2.1221884906961743}. Best is trial 11 with value: 0.6854539589871894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:48:15,267] Trial 22 finished with value: 0.684791584984768 and parameters: {'n_estimators': 1200, 'learning_rate': 0.005297930950828994, 'num_leaves': 79, 'min_data_in_leaf': 60, 'subsample': 0.7025458007472759, 'colsample_bytree': 0.9368339256711523, 'reg_lambda': 0.575738894401147, 'reg_alpha': 1.761722061669005}. Best is trial 22 with value: 0.684791584984768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:48:37,082] Trial 23 finished with value: 0.6849216038835994 and parameters: {'n_estimators': 1400, 'learning_rate': 0.005088764162022918, 'num_leaves': 79, 'min_data_in_leaf': 50, 'subsample': 0.782804675609348, 'colsample_bytree': 0.942123097828612, 'reg_lambda': 0.495107517247728, 'reg_alpha': 1.7380772726630676}. Best is trial 22 with value: 0.684791584984768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:49:11,734] Trial 24 finished with value: 0.6851216140943645 and parameters: {'n_estimators': 1400, 'learning_rate': 0.005059620975609049, 'num_leaves': 111, 'min_data_in_leaf': 40, 'subsample': 0.7670456787571096, 'colsample_bytree': 0.9400922229231039, 'reg_lambda': 1.0385091797390378, 'reg_alpha': 1.69017491567238}. Best is trial 22 with value: 0.684791584984768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:49:52,559] Trial 25 finished with value: 0.6853995955181887 and parameters: {'n_estimators': 1800, 'learning_rate': 0.005145834352608521, 'num_leaves': 111, 'min_data_in_leaf': 40, 'subsample': 0.7691113907251793, 'colsample_bytree': 0.8816636561410796, 'reg_lambda': 1.1429925482136962, 'reg_alpha': 1.350739153162504}. Best is trial 22 with value: 0.684791584984768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:50:18,958] Trial 26 finished with value: 0.6853107818185508 and parameters: {'n_estimators': 1400, 'learning_rate': 0.0058128846244499995, 'num_leaves': 111, 'min_data_in_leaf': 20, 'subsample': 0.7275466834280288, 'colsample_bytree': 0.9413446409799529, 'reg_lambda': 0.2394949229131682, 'reg_alpha': 1.0836356940619267}. Best is trial 22 with value: 0.684791584984768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:50:51,730] Trial 27 finished with value: 0.685167283001098 and parameters: {'n_estimators': 1600, 'learning_rate': 0.00586641356210261, 'num_leaves': 95, 'min_data_in_leaf': 40, 'subsample': 0.770448128509426, 'colsample_bytree': 0.942001547267435, 'reg_lambda': 0.9202275043769373, 'reg_alpha': 1.7097808518372586}. Best is trial 22 with value: 0.684791584984768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:51:45,797] Trial 28 finished with value: 0.6878094888023062 and parameters: {'n_estimators': 2000, 'learning_rate': 0.007617293174444146, 'num_leaves': 127, 'min_data_in_leaf': 50, 'subsample': 0.7300566543391459, 'colsample_bytree': 0.8848822548229961, 'reg_lambda': 1.651225298027351, 'reg_alpha': 1.480386126145145}. Best is trial 22 with value: 0.684791584984768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
      "[LightGBM] [Info] Number of positive: 61416, number of negative: 61416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11042\n",
      "[LightGBM] [Info] Number of data points in the train set: 122832, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-10 17:52:47,987] Trial 29 finished with value: 0.6867441486407846 and parameters: {'n_estimators': 2000, 'learning_rate': 0.005930753607439497, 'num_leaves': 159, 'min_data_in_leaf': 30, 'subsample': 0.7689546508985311, 'colsample_bytree': 0.9242415425214073, 'reg_lambda': 0.7626390194672624, 'reg_alpha': 0.7006447216838254}. Best is trial 22 with value: 0.684791584984768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 1200, 'learning_rate': 0.005297930950828994, 'num_leaves': 79, 'min_data_in_leaf': 60, 'subsample': 0.7025458007472759, 'colsample_bytree': 0.9368339256711523, 'reg_lambda': 0.575738894401147, 'reg_alpha': 1.761722061669005}\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Info] Number of positive: 68240, number of negative: 68240\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11072\n",
      "[LightGBM] [Info] Number of data points in the train set: 136480, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\data_analysis\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "\n",
      "Tuned LGBM — Holdout\n",
      "LogLoss: 0.6955443480241135\n",
      "ROC-AUC: 0.5902593324681227\n",
      "Brier  : 0.2500817242083936\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# --- time-aware 3-fold CV on the TRAIN window only ---\n",
    "# sort train indices by time\n",
    "train_idx = np.where(train_mask)[0]\n",
    "order = np.argsort(time_key[train_mask])\n",
    "train_idx = train_idx[order]\n",
    "\n",
    "def time_folds(idx, n_folds=3):\n",
    "    splits = np.array_split(idx, n_folds)\n",
    "    for i in range(n_folds):\n",
    "        va = splits[i]\n",
    "        tr = np.concatenate([splits[j] for j in range(n_folds) if j != i])\n",
    "        yield tr, va\n",
    "\n",
    "def objective(trial):\n",
    "    params = dict(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 800, 2500, step=200),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 0.004, 0.02, log=True),\n",
    "        num_leaves=trial.suggest_int(\"num_leaves\", 63, 191, step=16),\n",
    "        min_data_in_leaf=trial.suggest_int(\"min_data_in_leaf\", 30, 120, step=10),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 3.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 3.0),\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    aucs = []\n",
    "    for tr, va in time_folds(train_idx, n_folds=3):\n",
    "        m = LGBMClassifier(**params)\n",
    "        m.fit(\n",
    "            X.iloc[tr], y[tr],\n",
    "            eval_set=[(X.iloc[va], y[va])],\n",
    "            eval_metric='auc',\n",
    "            callbacks=[early_stopping(100), log_evaluation(0)]\n",
    "        )\n",
    "        p = m.predict_proba(X.iloc[va])[:,1]\n",
    "        aucs.append(roc_auc_score(y[va], p))\n",
    "    return 1 - np.mean(aucs)  # minimize (1-AUC)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=False)\n",
    "best_params = study.best_params\n",
    "best_params.update(dict(class_weight='balanced', random_state=42, n_jobs=-1))\n",
    "print(\"Best params:\", best_params)\n",
    "\n",
    "# --- retrain on full train, calibrate on cal, test on holdout ---\n",
    "final = LGBMClassifier(**best_params)\n",
    "# optional inner-early stopping on last 10% of train window\n",
    "tr_time = time_key[train_mask]; q90 = np.quantile(tr_time, 0.90)\n",
    "inner_tr = train_mask & (time_key <= q90)\n",
    "inner_va = train_mask & (time_key >  q90)\n",
    "final.fit(X[inner_tr], y[inner_tr],\n",
    "          eval_set=[(X[inner_va], y[inner_va])],\n",
    "          eval_metric='logloss',\n",
    "          callbacks=[early_stopping(100), log_evaluation(0)])\n",
    "\n",
    "# calibrate with sigmoid on cal window\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "calibrated = CalibratedClassifierCV(final, cv='prefit', method='sigmoid').fit(X[cal_mask], y[cal_mask])\n",
    "\n",
    "p_test = calibrated.predict_proba(X[test_mask])[:,1]\n",
    "print(\"\\nTuned LGBM (proper) — Holdout\")\n",
    "print(\"LogLoss:\", log_loss(y[test_mask], p_test))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y[test_mask], p_test))\n",
    "print(\"Brier  :\", brier_score_loss(y[test_mask], p_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb7b3c",
   "metadata": {},
   "source": [
    "### Sanity-Check 0 — Context\n",
    "We assume you already have these variables from the notebook:\n",
    "- `team_tall`  : the per-team dataset (2 rows per game)\n",
    "- `USED_FEATS` : the list of feature column names used to train\n",
    "- `X, y`       : features (DataFrame) and labels (numpy array)\n",
    "- `groups`     : `game_id` for GroupKFold\n",
    "- `time_key`   : `game_max_id` (time proxy per game)\n",
    "- masks: `train_mask`, `cal_mask`, `test_mask`\n",
    "- models: `final` (LightGBM before calibration), `calibrated` (after isotonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43424ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss\n",
    "\n",
    "# # Raw (uncalibrated) predictions on holdout\n",
    "# p_test_raw = final.predict_proba(X[test_mask])[:, 1]\n",
    "# print(\"RAW (no calibration) — holdout\")\n",
    "# print(\"LogLoss:\", log_loss(y[test_mask], p_test_raw))\n",
    "# print(\"AUC    :\", roc_auc_score(y[test_mask], p_test_raw))\n",
    "# print(\"Brier  :\", brier_score_loss(y[test_mask], p_test_raw))\n",
    "\n",
    "# # Calibrated (your current numbers)\n",
    "# p_test_cal = calibrated.predict_proba(X[test_mask])[:, 1]\n",
    "# print(\"\\nCALIBRATED — holdout\")\n",
    "# print(\"LogLoss:\", log_loss(y[test_mask], p_test_cal))\n",
    "# print(\"AUC    :\", roc_auc_score(y[test_mask], p_test_cal))\n",
    "# print(\"Brier  :\", brier_score_loss(y[test_mask], p_test_cal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0aa1c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.default_rng(42)\n",
    "# y_shuffled = y.copy()\n",
    "# y_shuffled[test_mask] = rng.permutation(y_shuffled[test_mask])\n",
    "\n",
    "# print(\"Label-shuffled holdout:\")\n",
    "# print(\"LogLoss:\", log_loss(y_shuffled[test_mask], p_test_cal))\n",
    "# print(\"AUC    :\", roc_auc_score(y_shuffled[test_mask], p_test_cal))\n",
    "# print(\"Brier  :\", brier_score_loss(y_shuffled[test_mask], p_test_cal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f72ffb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle the order of X within the holdout\n",
    "# X_test = X[test_mask].copy()\n",
    "# X_test_shuffled = X_test.sample(frac=1.0, random_state=123)\n",
    "\n",
    "# # Predict on shuffled features (same trained model)\n",
    "# p_test_shufX = calibrated.predict_proba(X_test_shuffled)[:, 1]\n",
    "\n",
    "# print(\"Feature-shuffled holdout:\")\n",
    "# print(\"LogLoss:\", log_loss(y[test_mask], p_test_shufX))\n",
    "# print(\"AUC    :\", roc_auc_score(y[test_mask], p_test_shufX))\n",
    "# print(\"Brier  :\", brier_score_loss(y[test_mask], p_test_shufX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e3ef431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suspects = {'team_win','team_win_team',\n",
    "#             'game_points','total_points',\n",
    "#             'game_bonus','game_autobonus','best_move_bonus',\n",
    "#             'killed_first','best_move'}\n",
    "# bad = [c for c in USED_FEATS if any(s in c for s in suspects)]\n",
    "# print(\"Forbidden features found:\", bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c284a",
   "metadata": {},
   "source": [
    "## 6) Convert to per-game winner & accuracy\n",
    "Pick the side with larger probability within each game on the holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a90fe3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-game accuracy (holdout): 0.5803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27188\\2849635908.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pred_side = hold.groupby('game_id').apply(lambda g: g.loc[g['proba'].idxmax(),'team'])\n"
     ]
    }
   ],
   "source": [
    "hold = team_tall.loc[test_mask, ['game_id','team','team_win_team']].copy()\n",
    "hold['proba'] = p_test\n",
    "\n",
    "# True side per game\n",
    "true_side = hold[hold['team_win_team']==1].groupby('game_id')['team'].first()\n",
    "\n",
    "# Predicted side by higher prob\n",
    "pred_side = hold.groupby('game_id').apply(lambda g: g.loc[g['proba'].idxmax(),'team'])\n",
    "acc = (pred_side == true_side.reindex(pred_side.index)).mean()\n",
    "print(\"Per-game accuracy (holdout):\", round(acc, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c98c4",
   "metadata": {},
   "source": [
    "## 7) Save model & inference helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f31981a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: artifacts_game\n",
      "Inference functions ready.\n"
     ]
    }
   ],
   "source": [
    "import joblib, json\n",
    "\n",
    "joblib.dump(calibrated, ARTS/\"lgbm_calibrated_pergame.joblib\")\n",
    "json.dump(USED_FEATS, open(ARTS/\"pergame_features.json\",\"w\"))\n",
    "print(\"Saved to:\", ARTS)\n",
    "\n",
    "def build_team_features_from_players(df_players: pd.DataFrame) -> pd.DataFrame:\n",
    "    w = compute_elo(df_players)\n",
    "    w = add_rolling_stats(w)\n",
    "\n",
    "    aggs = {\n",
    "        'pre_elo': ['mean','std','min','max', q25, q75],\n",
    "        'roll5_win_rate': ['mean'],\n",
    "        'roll20_win_rate': ['mean'],\n",
    "        'career_win_rate': ['mean'],\n",
    "        'games_played': ['mean','min','max', 'std']\n",
    "    }\n",
    "    if 'roll5_pts_mean' in w.columns:\n",
    "        aggs['roll5_pts_mean'] = ['mean']\n",
    "    if 'roll20_pts_mean' in w.columns:\n",
    "        aggs['roll20_pts_mean'] = ['mean']\n",
    "\n",
    "    ta = w.groupby(['game_id','team']).agg(aggs)\n",
    "    ta.columns = ['_'.join(filter(None, map(str, c))).replace('<function ','').replace('>','') for c in ta.columns]\n",
    "    ta = ta.reset_index()\n",
    "    if 'id' in w.columns:\n",
    "        gmaxid = w.groupby('game_id')['id'].max().rename('game_max_id')\n",
    "        ta = ta.merge(gmaxid, on='game_id', how='left')\n",
    "\n",
    "    wide = ta.pivot(index='game_id', columns='team')\n",
    "    wide.columns = [f\"{a}__{b}\" for a,b in wide.columns]\n",
    "    wide = wide.reset_index()\n",
    "\n",
    "    def side_cols(side): return [c for c in wide.columns if c.endswith(f\"__{side}\") and c != 'game_id']\n",
    "    maf_cols = side_cols('mafia')\n",
    "\n",
    "    delta = pd.DataFrame({'game_id': wide['game_id']})\n",
    "    for mcol in maf_cols:\n",
    "        base = mcol[:-len(\"__mafia\")]\n",
    "        ccol = base + \"__citizens\"\n",
    "        if ccol in wide.columns:\n",
    "            delta[base + \"__delta_maf_minus_cit\"] = wide[mcol] - wide[ccol]\n",
    "\n",
    "    team_tall_new = ta.merge(delta, on='game_id', how='left')\n",
    "    return team_tall_new\n",
    "\n",
    "def predict_game_winner_from_players(df_players_new: pd.DataFrame):\n",
    "    tt = build_team_features_from_players(df_players_new)\n",
    "    X_new = tt[USED_FEATS].fillna(0)\n",
    "    proba = calibrated.predict_proba(X_new)[:,1]\n",
    "    out = tt[['game_id','team']].copy()\n",
    "    out['p_team_win'] = proba\n",
    "    winners = out.loc[out.groupby('game_id')['p_team_win'].idxmax()].rename(columns={'team':'pred_team'})\n",
    "    winners = winners[['game_id','pred_team','p_team_win']]\n",
    "    return out, winners\n",
    "\n",
    "print(\"Inference functions ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4a7bc",
   "metadata": {},
   "source": [
    "## 8) “Daily” monitoring (simulated)\n",
    "Score newest ~2% of games by `game_max_id` to catch recent drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d11514c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "DAILY LogLoss: 0.6909885399496766\n",
      "DAILY ROC-AUC: 0.5954606325283922\n",
      "DAILY Brier  : 0.2479330190642982\n"
     ]
    }
   ],
   "source": [
    "cut = np.quantile(time_key, 0.98)\n",
    "daily_mask = time_key > cut\n",
    "p_daily = calibrated.predict_proba(X[daily_mask])[:,1]\n",
    "print(\"DAILY LogLoss:\", log_loss(y[daily_mask], p_daily))\n",
    "print(\"DAILY ROC-AUC:\", roc_auc_score(y[daily_mask], p_daily))\n",
    "print(\"DAILY Brier  :\", brier_score_loss(y[daily_mask], p_daily))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
